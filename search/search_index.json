{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Guide to using Django with Zappa \u00b6 This repo exists to document the process of getting a standard Django project running live in AWS Lambda using the zappa project . We will explore various configurations in a building-block fashion in the hopes that folks can leverage only the relevant parts for their needs. Video Tutorials \u00b6 I've written a course about using Zappa with Django with complete video tutorials. It's called Newline's Serverless Django with Zappa and it's available now. Tip All the content here is the same, but in the video course, we do a complete walk-through step-by-step to show all the details. Including, but not limited to: guide through the AWS Console and setting up your system to use Docker to create a repeatable, robust environment. Setup your Environment \u00b6 It is important to read this section in order to establish your working environment: Setup your Environment Walkthroughs \u00b6 Core Django Setup \u00b6 This section documents setting up a Django project with only core Python functionality responding to HTTP calls. The value of this core walkthrough could be to power an API driven compute engine or a event-driven data processing tool without the need to provide a UI. Hosting Static Files \u00b6 Generally if you'd like to use your Django project to present a User Interface (UI) then you'll need to display Images and CSS and serve Javascript files. These are known as static files and to deliver them using Zappa is unlike the traditional method of hosting the static files on a Linux or Windows box. This walkthrough documents one way of hosting the files on AWS S3. Using a Database \u00b6 This walkthough documents the steps necessary to connect your application to a hosted database. Using a Custom Domain Name \u00b6 Let's face it, the default urls provided by Zappa via API Gateway are ugly. Read this walkthrough to get a sense of what it takes to make the urls much more user friendly without a dedicated proxy service. Application Adaptations \u00b6 Running code in AWS Lambda is not the same as running code on a dedicated virtual server. This document describes differences in the AWS Lambda environment and outlines many of the possible adaptations you may need to apply to your application.","title":"Home"},{"location":"#guide-to-using-django-with-zappa","text":"This repo exists to document the process of getting a standard Django project running live in AWS Lambda using the zappa project . We will explore various configurations in a building-block fashion in the hopes that folks can leverage only the relevant parts for their needs.","title":"Guide to using Django with Zappa"},{"location":"#video-tutorials","text":"I've written a course about using Zappa with Django with complete video tutorials. It's called Newline's Serverless Django with Zappa and it's available now. Tip All the content here is the same, but in the video course, we do a complete walk-through step-by-step to show all the details. Including, but not limited to: guide through the AWS Console and setting up your system to use Docker to create a repeatable, robust environment.","title":"Video Tutorials"},{"location":"#setup-your-environment","text":"It is important to read this section in order to establish your working environment: Setup your Environment","title":"Setup your Environment"},{"location":"#walkthroughs","text":"","title":"Walkthroughs"},{"location":"#core-django-setup","text":"This section documents setting up a Django project with only core Python functionality responding to HTTP calls. The value of this core walkthrough could be to power an API driven compute engine or a event-driven data processing tool without the need to provide a UI.","title":"Core Django Setup"},{"location":"#hosting-static-files","text":"Generally if you'd like to use your Django project to present a User Interface (UI) then you'll need to display Images and CSS and serve Javascript files. These are known as static files and to deliver them using Zappa is unlike the traditional method of hosting the static files on a Linux or Windows box. This walkthrough documents one way of hosting the files on AWS S3.","title":"Hosting Static Files"},{"location":"#using-a-database","text":"This walkthough documents the steps necessary to connect your application to a hosted database.","title":"Using a Database"},{"location":"#using-a-custom-domain-name","text":"Let's face it, the default urls provided by Zappa via API Gateway are ugly. Read this walkthrough to get a sense of what it takes to make the urls much more user friendly without a dedicated proxy service.","title":"Using a Custom Domain Name"},{"location":"#application-adaptations","text":"Running code in AWS Lambda is not the same as running code on a dedicated virtual server. This document describes differences in the AWS Lambda environment and outlines many of the possible adaptations you may need to apply to your application.","title":"Application Adaptations"},{"location":"additional/","text":"Additional Resources \u00b6 This site powered by mkdocs and powered by github. Source documents are here: https://github.com/edgarroman/zappa-django-guide","title":"Additional"},{"location":"additional/#additional-resources","text":"This site powered by mkdocs and powered by github. Source documents are here: https://github.com/edgarroman/zappa-django-guide","title":"Additional Resources"},{"location":"aws_acm/","text":"AWS Certificate Manager (ACM) \u00b6 This page lists various activites that may be necessary to perform when leveraging Zappa Request a Certificate \u00b6 ACM provides digital certificates for free but the certificates can only be used with Elastic Load Balancing and Amazon CloudFront . Warning To use ACM with Zappa, you must create or import the certificate in the US East (N. Virginia) (us-east-1). See AWS documentation for more details. Navigate to the ACM Console and click Request a Certificate In 'Add a Domain name' enter Note that we entered both the 'www' subdomain and the apex of the domain. This allows users to leverage either url and have it covered with a single certificate. More info can be found in the AWS ACM documentation on Requesting a Certificate Warning Carefully consider which domains shall be covered by this certificate because once it is validated, you cannot modify the list of domains. Any changes will require a new certificate to be issued. Select validation method ACM needs a way to confirm that you own the domain. So you must select either DNS Validation or Email validation . Click on Review and Request You should see a confirmation message similar to the image below (showing email validation): Email validation If you chose email method of domain ownership validation, an email is sent to the registered contact address in the WHOIS for the domain. In addition, a few select email addresses are also included. Full validation rules are posted in ACM Documentation. Check your email for validation links You should receive at least one email for each domain you entered. You may actually get multiple email addresses because sometimes registered emails are duplicated for Techincal or Administrative contacts in the WHOIS information. The emails should be similar to: Click on all the validation links You must click on the validation link for every domain name included in step 2 above . The digital certificate will not be issued until all domains have been verified. And then: Record the ARN for the digital certificate You will use the ARN for other purposes. The ARN is displayed on the verification page but also in the details page for the certificate in the ACM console.","title":"AWS Certificate Manager (ACM)"},{"location":"aws_acm/#aws-certificate-manager-acm","text":"This page lists various activites that may be necessary to perform when leveraging Zappa","title":"AWS Certificate Manager (ACM)"},{"location":"aws_acm/#request-a-certificate","text":"ACM provides digital certificates for free but the certificates can only be used with Elastic Load Balancing and Amazon CloudFront . Warning To use ACM with Zappa, you must create or import the certificate in the US East (N. Virginia) (us-east-1). See AWS documentation for more details. Navigate to the ACM Console and click Request a Certificate In 'Add a Domain name' enter Note that we entered both the 'www' subdomain and the apex of the domain. This allows users to leverage either url and have it covered with a single certificate. More info can be found in the AWS ACM documentation on Requesting a Certificate Warning Carefully consider which domains shall be covered by this certificate because once it is validated, you cannot modify the list of domains. Any changes will require a new certificate to be issued. Select validation method ACM needs a way to confirm that you own the domain. So you must select either DNS Validation or Email validation . Click on Review and Request You should see a confirmation message similar to the image below (showing email validation): Email validation If you chose email method of domain ownership validation, an email is sent to the registered contact address in the WHOIS for the domain. In addition, a few select email addresses are also included. Full validation rules are posted in ACM Documentation. Check your email for validation links You should receive at least one email for each domain you entered. You may actually get multiple email addresses because sometimes registered emails are duplicated for Techincal or Administrative contacts in the WHOIS information. The emails should be similar to: Click on all the validation links You must click on the validation link for every domain name included in step 2 above . The digital certificate will not be issued until all domains have been verified. And then: Record the ARN for the digital certificate You will use the ARN for other purposes. The ARN is displayed on the verification page but also in the details page for the certificate in the ACM console.","title":"Request a Certificate"},{"location":"aws_credentials/","text":"Managing AWS Credentials \u00b6 Getting Started with AWS and Zappa \u00b6 Details in this section are light because this information is documented well elsewhere on the web. Create AWS Account if you haven't already Create an S3 bucket. For purposes of this walkthrough I have used the bucket name of zappatest-code in the 'US Standard' region. This bucket will be used by zappa as a mechanism to upload your project into the lambda environment. Thus it will generally be empty except during the brief time you are deploying the project. Create an IAM User with API keys Easier said than done. The quick and easy way of doing this is to create a user with a policy that allows a very broad set of permissions. However, this is not great from a security perspective. There is an ongoing discussion about the exact set of permissions needed. Now we need to allow scripts and local programs to get the credentials created above. You have some options for this: Setup Local Account Credentials \u00b6 Set environment variables This is very easy but must be done for each bash console you are using. export AWS_ACCESS_KEY_ID=<your key here> export AWS_SECRET_ACCESS_KEY=<your secret access key here> Create a local credentials file ( ~/.aws/credentials on Linux, or OS X) Probably a better long term solution since you can store multiple sets of keys for different environments using profiles. In addition, you can provide multiple profiles that provides some isolation between AWS accounts and/or roles. The alternate profile example shown below is called 'zappa' [default] aws_access_key_id = your_access_key_id aws_secret_access_key = your_secret_access_key [zappa] aws_access_key_id = your_access_key_id_specific_to_zappa aws_secret_access_key = your_secret_access_key_specific_to_zappa Since you have multiple profiles, it is recommended that you use an environment variable to distinguish which profile is desired to be active. Shown here is an example of using the 'zappa' profile: export AWS_PROFILE = zappa Useful links for Windows or more information: \u00b6 http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials","title":"Managing Credentials"},{"location":"aws_credentials/#managing-aws-credentials","text":"","title":"Managing AWS Credentials"},{"location":"aws_credentials/#getting-started-with-aws-and-zappa","text":"Details in this section are light because this information is documented well elsewhere on the web. Create AWS Account if you haven't already Create an S3 bucket. For purposes of this walkthrough I have used the bucket name of zappatest-code in the 'US Standard' region. This bucket will be used by zappa as a mechanism to upload your project into the lambda environment. Thus it will generally be empty except during the brief time you are deploying the project. Create an IAM User with API keys Easier said than done. The quick and easy way of doing this is to create a user with a policy that allows a very broad set of permissions. However, this is not great from a security perspective. There is an ongoing discussion about the exact set of permissions needed. Now we need to allow scripts and local programs to get the credentials created above. You have some options for this:","title":"Getting Started with AWS and Zappa"},{"location":"aws_credentials/#setup-local-account-credentials","text":"Set environment variables This is very easy but must be done for each bash console you are using. export AWS_ACCESS_KEY_ID=<your key here> export AWS_SECRET_ACCESS_KEY=<your secret access key here> Create a local credentials file ( ~/.aws/credentials on Linux, or OS X) Probably a better long term solution since you can store multiple sets of keys for different environments using profiles. In addition, you can provide multiple profiles that provides some isolation between AWS accounts and/or roles. The alternate profile example shown below is called 'zappa' [default] aws_access_key_id = your_access_key_id aws_secret_access_key = your_secret_access_key [zappa] aws_access_key_id = your_access_key_id_specific_to_zappa aws_secret_access_key = your_secret_access_key_specific_to_zappa Since you have multiple profiles, it is recommended that you use an environment variable to distinguish which profile is desired to be active. Shown here is an example of using the 'zappa' profile: export AWS_PROFILE = zappa","title":"Setup Local Account Credentials"},{"location":"aws_credentials/#useful-links-for-windows-or-more-information","text":"http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials","title":"Useful links for Windows or more information:"},{"location":"aws_database/","text":"Creating an RDS Database \u00b6 There are a number of RDS engines available - https://aws.amazon.com/rds/getting-started/. Another choice is to opt for DynamoDB - https://aws.amazon.com/dynamodb/getting-started/ Adding second private subnet to VPC \u00b6 RDS requires additional subnet to create an instance. Follow step 3 Create Additional Subnets at https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-public-private-vpc.html to add one to your existing VPC. Choose an Availability Zone different from the first one and IPv4 CIDR block 10.0.2.0/24. Creating an RDS instance \u00b6 Follow this guide https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.CreatingConnecting.PostgreSQL.html keeping in mind parameters we created before.","title":"Creating an RDS Database"},{"location":"aws_database/#creating-an-rds-database","text":"There are a number of RDS engines available - https://aws.amazon.com/rds/getting-started/. Another choice is to opt for DynamoDB - https://aws.amazon.com/dynamodb/getting-started/","title":"Creating an RDS Database"},{"location":"aws_database/#adding-second-private-subnet-to-vpc","text":"RDS requires additional subnet to create an instance. Follow step 3 Create Additional Subnets at https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-public-private-vpc.html to add one to your existing VPC. Choose an Availability Zone different from the first one and IPv4 CIDR block 10.0.2.0/24.","title":"Adding second private subnet to VPC"},{"location":"aws_database/#creating-an-rds-instance","text":"Follow this guide https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.CreatingConnecting.PostgreSQL.html keeping in mind parameters we created before.","title":"Creating an RDS instance"},{"location":"aws_network/","text":"Adventures in Networking \u00b6 Presumably, since you've read this far, you're interested in more than a simple Django powered API serving static images. You probably want something that is more interactive with users and have advanced capabilities. So this will require interacting with additional AWS services like RDS or DynamoDB for database services, SNS or SQS for task processing, and many more... Well, there is an important aspect about interacting with additional AWS services. With pure AWS lambda, we have a fairly low attack surface, but when we introduce additional interactions over the network, we must consider information security risks and our network architecture. Note This section assumes some familarity with the basic concepts within AWS VPC. If you aren't comfortable with these concepts, then head over to a Primer on AWS VPC Networking A simple, but naive approach \u00b6 A simple approach would be to create an AWS RDS instance that is open to the Internet and have your lambda Django project login directly. While this may work, this approach is fraught with peril. Numerous vulnerabilities could exist and credentials could be discovered by brute force. Even without gaining access to your RDS, it is trivial to launch a denial-of-service attack to ensure your Django project has no database services. Basically, do not do this. That's why Amazon has VPC \u00b6 Introducing AWS Virtual Private Cloud (VPC). This service provides a way of segmenting Internet traffic from your other AWS services. This feature is incredibly valuable to securing our project, so that bad guys have the smallest attack surface possible. Once a VPC is established, you can then subdivide the VPC into subnets. Which are little non-overlapping IP chunks of the overall VPC. Like dividing a pie into slices. It is important to realize that you have almost entire control of your IP space when you define your VPC and associated subnets. You are creating a Software Defined Network (SDN) and you have a lot of leeway. With this freedom comes choices and important considerations on how you design your network. The Essential VPC and Subnet Configuration \u00b6 Here is the absolute minimum you must have to have a working Django site within a VPC: A VPC A subnet within the VPC A security group Your zappa project configured to use the subnet and security group There are no need for routes, NAT gateways, Internet gateways, or even allowing inbound rules on the security group. You will probably need many of these services eventually for a robust and full-featured application, but for illustration purposes now, we will keep it simple. You may be asking yourself how will traffic from the Internet reach the lambda function. Well essentially the magic is in the API Gateway that zappa creates on deployment. From the API Gateway FAQ : Amazon API Gateway endpoints are always public to the Internet. Proxy requests to backend operations also need to be publicly accessible on the Internet. However, you can generate a client-side SSL certificate in Amazon API Gateway to verify that requests to your backend systems were sent by API Gateway using the public key of the certificate. So API Gateways act as an 'always-on' Internet facing service that sends the HTTP requests to the Zappa Lambda functions by creating Lambda events. These events can reach your zappa application even if deployed in a top-secret lockbox. Note that in the above VPC setup the Lambda function is completely isolated from direct access to the Internet. Thus the Lambda functions can't make outbound connections to anything: other servers, databases, S3, etc. Let's face it, there's no real point to going through the effort of doing this if the Lambda functions are really this isolated. But the reason this information is important is because in order to leverage other AWS resources, the VPC lays the foundation to do this securely. Extending the VPC \u00b6 To re-iterate: we don't need a VPC network to make the Zappa Lambda-powered Django site visible on the Internet. We need to extend the VPC so that we can add more AWS services like: Adding an RDS database that is only accessible from our Lambda functions Adding an S3 bucket Allowing Lambda functions to communicate to traditional EC2 instances for long running processes Allowing the Lambda functions to access the Internet to hit an external API Ability to interact with SQS and/or SNS The important thing is that we can enable all these scenarios in a secure manner. There are too many scenarios to go into detail here, so we will provide some guidelines. Next we learn about the common patterns of VPC usage and try to identify usage options. One warning before we go on with VPC subnet sizing and Lambda: When Lambda functions fire, they must be assigned an IP address temporarily. If you have a lot of Lambda functions firing, then you must have a lot of IP addresses available in your subnet. You can learn more here . VPC Patterns \u00b6 While the actual VPC itself is very straightforward, the combination of subnets within the VPC can take many forms. Additionally, you must consider how the subnets will communicate among themselves as well as how they communicate with outside networks. For a more comprehensive list of options and other valuable information about VPCs, see this link: https://aws.amazon.com/answers/networking/aws-single-vpc-design/ The options are summarized here: VPC with a single Internet-Accessible subnet \u00b6 This pattern places your lambda functions, your RDS, and additional SNS/SQS services in a single subnet that is Internet accessible in your VPC. In theory you could configure your security groups to ensure only lambda functions can hit your RDS. One advantage of this setup is that you can setup your local machine to connect to your RDS without a bastion host . Just restrict access based on IP. Important note - you will want to ensure careful inbound IP restrictions. While it's great that you can connect to RDS with your SQL desktop client, you should setup a bastion host . Also note that your zappa deployment will not have outbound access to the Internet . In order to do this you will have use a Public/Private setup. Some additional considerations from the AWS Documentation Some additional considerations from the AWS Documentation We recommend that you avoid DNS resolution of public host names for your VPC. This can take several seconds to resolve, which adds several seconds of billable time on your request. For example, if your Lambda function accesses an Amazon RDS instance in your VPC, launch the instance with the no-publicly-accessible option. When you add VPC configuration to a Lambda function, it can only access resources in that VPC. If a Lambda function needs to access both VPC resources and the public Internet, the VPC needs to have a Network Address Translation (NAT) instance inside the VPC. When a Lambda function is configured to run within a VPC, it incurs an additional ENI start-up penalty. This means address resolution may be delayed when trying to connect to network resources. This scenario is good for straightforward setups with a little work, but has significant limitations VPC with a Public subnet and Private subnet \u00b6 Arguably the most flexible and future-proof of all web application setups. You have two subnets: one public and one private. Your RDS and lambda functions reside in the private subnet, far away from bad guys, but also far away from your local machine. In order to access the database from your system you will need a bastion host in the public subnet. Another advantage of this setup is that if you ever want to add additional EC2-based services that need to interact with the Internet you can do this very easily without compromising security. Generally this setup will require networking knowledge to setup the Internet gateway, bastion host, and NAT Gateway. The upshot is this configuration is the most secure and most flexible for your growth but will be complex from a network standpoint On-Premises and Internet-Accessible VPC \u00b6 Same as the last configuration, but if you have an internal corporate network to connect, you can easily establish a connection to the private subnet without compromising security. If you thought the last setup was complex, you better know what you are doing from a network standpoint. A good solution if you need to connect an internal corporate network VPC with an Internal-Only subnet \u00b6 Obviously a very special case of creating a Django app for internal use only with no desire to have it accessible by the Internet. This is actually most secure. Since you can access any of the resources from your desktop on the internal network. Not bad for the paranoid or security conscious devops team. Useful for the simple environment if you have an existing secure network Subdividing the VPC \u00b6 Once you get a VPC selected you must create subnets within the VPC. When defining a subnet, you just have to pick a non-overlapping segment of the ip range. So if you have VPC that spans IP address 10.5.0.1 to 10.5.0.254, then you pick contiguous segments within this range. See more details in Primer on AWS VPC Networking Examples for Walkthroughs \u00b6 For the purposes of walkthroughs, we will leverage a simple VPC with a single subnet. A single subnet will generally be enough to guide readers through the scenarios. We have a VPC: id: vpc-9a9a1dfc cidr: 10.6.0.0/16 With subnet: id: subnet-f3446aba cidr: 10.6.1.0/24 And security group: id: sg-13a5736f inbound rules: none outbound rules: all traffic TODO: Show example zappa configuration here Note on Redundancy \u00b6 While these examples are all using a single subnet for clarity, in production you will want to create multiple subnets within the VPC all with different availability zones. This ensures if there is a failure within a single availability zone, there are alternate paths. The general approach is to associate the Lambda functions with multiple subnets and the AWS resources with the same multiple subnets (e.g. RDS).","title":"Adventures in Networking"},{"location":"aws_network/#adventures-in-networking","text":"Presumably, since you've read this far, you're interested in more than a simple Django powered API serving static images. You probably want something that is more interactive with users and have advanced capabilities. So this will require interacting with additional AWS services like RDS or DynamoDB for database services, SNS or SQS for task processing, and many more... Well, there is an important aspect about interacting with additional AWS services. With pure AWS lambda, we have a fairly low attack surface, but when we introduce additional interactions over the network, we must consider information security risks and our network architecture. Note This section assumes some familarity with the basic concepts within AWS VPC. If you aren't comfortable with these concepts, then head over to a Primer on AWS VPC Networking","title":"Adventures in Networking"},{"location":"aws_network/#a-simple-but-naive-approach","text":"A simple approach would be to create an AWS RDS instance that is open to the Internet and have your lambda Django project login directly. While this may work, this approach is fraught with peril. Numerous vulnerabilities could exist and credentials could be discovered by brute force. Even without gaining access to your RDS, it is trivial to launch a denial-of-service attack to ensure your Django project has no database services. Basically, do not do this.","title":"A simple, but naive approach"},{"location":"aws_network/#thats-why-amazon-has-vpc","text":"Introducing AWS Virtual Private Cloud (VPC). This service provides a way of segmenting Internet traffic from your other AWS services. This feature is incredibly valuable to securing our project, so that bad guys have the smallest attack surface possible. Once a VPC is established, you can then subdivide the VPC into subnets. Which are little non-overlapping IP chunks of the overall VPC. Like dividing a pie into slices. It is important to realize that you have almost entire control of your IP space when you define your VPC and associated subnets. You are creating a Software Defined Network (SDN) and you have a lot of leeway. With this freedom comes choices and important considerations on how you design your network.","title":"That's why Amazon has VPC"},{"location":"aws_network/#the-essential-vpc-and-subnet-configuration","text":"Here is the absolute minimum you must have to have a working Django site within a VPC: A VPC A subnet within the VPC A security group Your zappa project configured to use the subnet and security group There are no need for routes, NAT gateways, Internet gateways, or even allowing inbound rules on the security group. You will probably need many of these services eventually for a robust and full-featured application, but for illustration purposes now, we will keep it simple. You may be asking yourself how will traffic from the Internet reach the lambda function. Well essentially the magic is in the API Gateway that zappa creates on deployment. From the API Gateway FAQ : Amazon API Gateway endpoints are always public to the Internet. Proxy requests to backend operations also need to be publicly accessible on the Internet. However, you can generate a client-side SSL certificate in Amazon API Gateway to verify that requests to your backend systems were sent by API Gateway using the public key of the certificate. So API Gateways act as an 'always-on' Internet facing service that sends the HTTP requests to the Zappa Lambda functions by creating Lambda events. These events can reach your zappa application even if deployed in a top-secret lockbox. Note that in the above VPC setup the Lambda function is completely isolated from direct access to the Internet. Thus the Lambda functions can't make outbound connections to anything: other servers, databases, S3, etc. Let's face it, there's no real point to going through the effort of doing this if the Lambda functions are really this isolated. But the reason this information is important is because in order to leverage other AWS resources, the VPC lays the foundation to do this securely.","title":"The Essential VPC and Subnet Configuration"},{"location":"aws_network/#extending-the-vpc","text":"To re-iterate: we don't need a VPC network to make the Zappa Lambda-powered Django site visible on the Internet. We need to extend the VPC so that we can add more AWS services like: Adding an RDS database that is only accessible from our Lambda functions Adding an S3 bucket Allowing Lambda functions to communicate to traditional EC2 instances for long running processes Allowing the Lambda functions to access the Internet to hit an external API Ability to interact with SQS and/or SNS The important thing is that we can enable all these scenarios in a secure manner. There are too many scenarios to go into detail here, so we will provide some guidelines. Next we learn about the common patterns of VPC usage and try to identify usage options. One warning before we go on with VPC subnet sizing and Lambda: When Lambda functions fire, they must be assigned an IP address temporarily. If you have a lot of Lambda functions firing, then you must have a lot of IP addresses available in your subnet. You can learn more here .","title":"Extending the VPC"},{"location":"aws_network/#vpc-patterns","text":"While the actual VPC itself is very straightforward, the combination of subnets within the VPC can take many forms. Additionally, you must consider how the subnets will communicate among themselves as well as how they communicate with outside networks. For a more comprehensive list of options and other valuable information about VPCs, see this link: https://aws.amazon.com/answers/networking/aws-single-vpc-design/ The options are summarized here:","title":"VPC Patterns"},{"location":"aws_network/#vpc-with-a-single-internet-accessible-subnet","text":"This pattern places your lambda functions, your RDS, and additional SNS/SQS services in a single subnet that is Internet accessible in your VPC. In theory you could configure your security groups to ensure only lambda functions can hit your RDS. One advantage of this setup is that you can setup your local machine to connect to your RDS without a bastion host . Just restrict access based on IP. Important note - you will want to ensure careful inbound IP restrictions. While it's great that you can connect to RDS with your SQL desktop client, you should setup a bastion host . Also note that your zappa deployment will not have outbound access to the Internet . In order to do this you will have use a Public/Private setup. Some additional considerations from the AWS Documentation Some additional considerations from the AWS Documentation We recommend that you avoid DNS resolution of public host names for your VPC. This can take several seconds to resolve, which adds several seconds of billable time on your request. For example, if your Lambda function accesses an Amazon RDS instance in your VPC, launch the instance with the no-publicly-accessible option. When you add VPC configuration to a Lambda function, it can only access resources in that VPC. If a Lambda function needs to access both VPC resources and the public Internet, the VPC needs to have a Network Address Translation (NAT) instance inside the VPC. When a Lambda function is configured to run within a VPC, it incurs an additional ENI start-up penalty. This means address resolution may be delayed when trying to connect to network resources. This scenario is good for straightforward setups with a little work, but has significant limitations","title":"VPC with a single Internet-Accessible subnet"},{"location":"aws_network/#vpc-with-a-public-subnet-and-private-subnet","text":"Arguably the most flexible and future-proof of all web application setups. You have two subnets: one public and one private. Your RDS and lambda functions reside in the private subnet, far away from bad guys, but also far away from your local machine. In order to access the database from your system you will need a bastion host in the public subnet. Another advantage of this setup is that if you ever want to add additional EC2-based services that need to interact with the Internet you can do this very easily without compromising security. Generally this setup will require networking knowledge to setup the Internet gateway, bastion host, and NAT Gateway. The upshot is this configuration is the most secure and most flexible for your growth but will be complex from a network standpoint","title":"VPC with a Public subnet and Private subnet"},{"location":"aws_network/#on-premises-and-internet-accessible-vpc","text":"Same as the last configuration, but if you have an internal corporate network to connect, you can easily establish a connection to the private subnet without compromising security. If you thought the last setup was complex, you better know what you are doing from a network standpoint. A good solution if you need to connect an internal corporate network","title":"On-Premises and Internet-Accessible VPC"},{"location":"aws_network/#vpc-with-an-internal-only-subnet","text":"Obviously a very special case of creating a Django app for internal use only with no desire to have it accessible by the Internet. This is actually most secure. Since you can access any of the resources from your desktop on the internal network. Not bad for the paranoid or security conscious devops team. Useful for the simple environment if you have an existing secure network","title":"VPC with an Internal-Only subnet"},{"location":"aws_network/#subdividing-the-vpc","text":"Once you get a VPC selected you must create subnets within the VPC. When defining a subnet, you just have to pick a non-overlapping segment of the ip range. So if you have VPC that spans IP address 10.5.0.1 to 10.5.0.254, then you pick contiguous segments within this range. See more details in Primer on AWS VPC Networking","title":"Subdividing the VPC"},{"location":"aws_network/#examples-for-walkthroughs","text":"For the purposes of walkthroughs, we will leverage a simple VPC with a single subnet. A single subnet will generally be enough to guide readers through the scenarios. We have a VPC: id: vpc-9a9a1dfc cidr: 10.6.0.0/16 With subnet: id: subnet-f3446aba cidr: 10.6.1.0/24 And security group: id: sg-13a5736f inbound rules: none outbound rules: all traffic TODO: Show example zappa configuration here","title":"Examples for Walkthroughs"},{"location":"aws_network/#note-on-redundancy","text":"While these examples are all using a single subnet for clarity, in production you will want to create multiple subnets within the VPC all with different availability zones. This ensures if there is a failure within a single availability zone, there are alternate paths. The general approach is to associate the Lambda functions with multiple subnets and the AWS resources with the same multiple subnets (e.g. RDS).","title":"Note on Redundancy"},{"location":"aws_network_primer/","text":"A Brief Primer on AWS VPC Networking (and how Lambda functions relate) \u00b6 Confused on how to create your network environment in AWS? Don't worry - you're in good company. Configuring and using AWS VPC networking is powerful, but complex. This document attempts to create a mental model to help readers understand the concepts and thus allow more reasonable decisions to be made. I find it helpful to draw analogies to traditional network setup within a company to assist building the mental model. If you're already familiar with AWS VPC, you can skip to how AWS Lambda interacts with VPC This document takes the general approach: First, discuss the concepts and talk about how they relate Link to good tutorials on how to create VPCs once the reader has a good understanding We won't go into exacting detail on how to do each step since there are many good tutorials already on the Interwebs. First there is a VPC \u00b6 Back in the bad old days, networks were created by plugging a bunch of network cables into network hardware and were statically configured. In AWS, the amazing thing is that you define the network dynamically by providing parameters to Amazon as a form of Software Defined Networking . So Amazon has hardware in their datacenters but present to users a very dynamic environment is nearly indistinguishable from an old-school network. The first thing most users do is define the overall boundaries of their network using a Virtual Private Cloud or VPC. This is roughly akin to drawing a circle around your infrastructure. The old-school equivalent would be to define your company's internal network space. This network space would allow your various departments to have computers that belong to this space. Old-school companies might have several floors and departments so it would have to be big enough to house all these computers. Additionally, you don't want external hackers have unfettered access to your internal databases and accounting systems so most companies pick Private Network Space to isolate the big bad Internet from the company network. You do this in AWS VPC by defining the IP network space of the total possible IP addresses that could live in the VPC. Now you may not have lots and lots of computers you'll need to put into your VPC, but fortunately you are not charged by Amazon on how many IP addresses you have reserved, so you can err on the side of having a bit of room. The private network ranges available are defined by an Internet 'standard' called RFC 1918 . The private network spaces for IPv4 are: 10.0.0.0 - 10.255.255.255 (10/8 prefix) 172.16.0.0 - 172.31.255.255 (172.16/12 prefix) 192.168.0.0 - 192.168.255.255 (192.168/16 prefix) AWS restricts creation of VPCs with a /16 CIDR mask which limits you to a VPC with 65,536 IP addresses (which is pretty big). This is probably a little excessive for your first VPC, so why not start with something like 10.0.0.0/20 which gives you about 4 thousand IP addresses? Later we'll keep dividing this network space so this is a good start. Now create your subnets \u00b6 Ok, so now we've got a range of IP addresses that we can use and a potential route to the Internet. Using our old-school network analogy, what a typical network engineer would do next is subdivide the network into chunks. And the more technical term of a chunk of the network is a subnet . In physical world, some possible reasons do this are: If a building has multiple floors, maybe one subnet per floor Maybe divide a subnet for each business department (e.g. HR subnet, IT subnet, Software Development subnet) Subnet based on functionality: one subnet for the phone system, one subnet for desktop computers, one subnet for web servers In the VPC world, the only real reasons needed to divide up the VPC is for functionality and security. A very common example would be if you want web application servers in a public subnet and database servers in a private subnet. In this configuration, users on the Internet can point their browsers at your website but cannot directly access your database servers. And you can create a special connection from your public subnet to your private subnet so that only the web application servers can connect to the database servers. In this way, you lessen the chances that bad actors can attack your database by restricting direct access. Notes on subnet calculations \u00b6 There are a lot of complex rules for how big and location of the subnets within the VPC, but there are two important constraints: The size of the subnets must be a power of 2 - which approximately results in the number of IP addresses assigned to the subnet (e.g. 2, 4, 8, 16, 32, 64, 128, 256, etc IP addresses available) The subnets must be contiguous - which means the available IP addresses in the chunk must be sequential By far, the easiest way to visualize this system is to use a tool that handles all the complications for you. I highly recommend the Spiceworks Subnet Calculator But there's more \u00b6 Just a few more notes about subnets created within your VPC. First, each subnet exists in one availability zone within one AWS Region. For your experimentation, this should not be a big deal. But once you have a production system that is designed to be highly-available, then you will probably have to eventually create multiple subnets that are doing the same function (e.g. hosting a database or application servers) to guard against the case when one availability zone is having troubles, your infrastructure still is up. See the AWS documentation for more info on Regions and Availability Zones . Each subnet has a built-in Access Control List (ACL) . This will let you control inbound and outbound network traffic at the TCP/IP level. Thus you can create rules that allow or restrict network traffic that applies to the entire subnet. This is an important distinction from a more robust firewall or security device: regardless of how many servers you may have in your subnet, they all share these rules. So if a particular external IP address is permitted in the ACL, then all servers could generate traffic to that external IP address. If more fine-grained control per resource is necessary, see VPC Security Groups . Lastly, there is a limit of 200 of subnets per VPC imposed by AWS at the time of this writing. Hooking things up: route tables \u00b6 Usually you'll want various subnets to communicate -- and by default, AWS allows all traffic to flow from any subnet to any another. So that's convenient but usually we want a better security posture. AWS VPC uses route tables to figure out how network traffic should be shuffled around. A route table is a configurable object within the AWS console. When you create a new VPC, the AWS system will automatically create a route table for you and assign it to your VPC. A VPC is always assigned to a route table; and that assigned route table is the 'main' route table. But there is no star, no icon, or anything special in the AWS console that this is a 'main' route table -- merely the fact that when you click on the VPC, only one route table will be listed there. And you cannot change a VPC 'main' route table. So this 'main' route table has some special properties. Turns out that each subnet is also assigned a route table. And if you don't explicitly assign a route table on creation of the subnet, it gloms onto whatever the current 'main' route table is. So the 'main' route table is used as a default for all subnets that aren't assigned a specific route table. Thus all the subnets will share a single route table by default unless you take action. By taking action, I mean you can assign a different route table to a subnet. Why do we need multiple route tables? \u00b6 The question you may be asking yourself is why do we even need more than one route table? The most common usage is to increase security by specializing the subnets. Since we know all the subnets are really just networks, there is no functional difference until we modify how network traffic flows between the subnets. Back to the example of web app servers and databases. We can put all the web app server instances in Subnet A and the database server instances in Subnet B. But then by restricting the routes so that Subnet B can only talk to Subnet A, we can consider Subnet B as 'private'. Again, there is no sticker, no emjoi, nor icon in the AWS console that designates Subnet B as 'private' except for the fact that we've associated a restricted route table. Conversely, we can allow Internet traffic to go out of Subnet A by assigning a different route table; thereby creating a 'public' subnet in name only. Talking to the Internet \u00b6 Usually, most applications will need to communicate with the Internet; either taking incoming network connections or retrieving information. In AWS you connect your VPC to the Internet using Internet Gateways . This is a special resource that is assigned to a VPC that allows network traffic to come in and out of your VPC. Internet Gateways are free to AWS users and can be created easily by using the VPC creation wizard or after the fact. An Internet Gateway can only be attached to a single VPC at a time and a VPC can only have up to one IG attached at a time. But VPCs do not have to have Internet Gateways attached. But creating an Internet Gateway and then associating it with a VPC is only the preparation work. In order to actually enable traffic into and out of a subnet, you must have a route associated with the subnet that connects the Internet Gateway. So for the subnet you wish to designate as 'public' you must add a route: Destination: 0.0.0.0/0 - This is a special indicator to the route table that works as a 'catch-all' for any network traffic destination not recognized Target: igw-name-of-your-ig - Use the AWS console identifer of the IG associated with the current VPC And presto! You can now consider any subnets associated with this route table as 'public' subnets. Any EC2 instance that is assigned an Elastic IP can now send and receive traffic from the Internet. Any EC2 instances without an Elastic IP will not be permitted to send and receive traffic. Other AWS Services \u00b6 Note that many of the AWS services are not associated with any VPC and thus can be considered accessible via Internet-only. For example, if your application living in the VPC needs to connect to the AWS Simple Queue Service (SQS), you will have to enable Internet access via an Internet Gateway as described above. Any AWS service that does not have a VPC endpoint capability is considered Internet only. At the time of this writing, only the following services have VPC endpoints (and thus would not need an Internet Gateway): S3 DynamoDB ElasticSearch In addition, some services like AWS RDS and ElastiCache can be assigned to VPC subnets and thus are natively accessible within a VPC. These services effectively provide fully managed EC2 instances that provide the services and thus can be assigned to one or more VPC subnets. Connectivity from private subnets \u00b6 Often, resources in 'private' subnets will have to communicate to the Internet. Usually, this network traffic is initiated from within the subnet and only return traffic is allowed. If outside network traffic were permitted to initiate communication to 'private' subnet servers, it would expose a potential security risk and thus is not allowed. The mechanism to allow servers and resources within a 'private' subnet to have outbound communication is to have the network traffic sent to a special resource called a NAT device. NAT stands for Network Address Translation and is generally used to hide a number of private servers or resources from any outside network. This NAT device must live in a 'public' subnet with access to the Internet since it acts as a middle-man for the network traffic: the private resources network traffics gets sent from the 'private' subnet to the 'public' subnet and the NAT device passes along the data as if the NAT device was initiating the connection. Enabling a server or resource in a 'private' subnet to communicate to the Internet consists of: Create the NAT Device (more on that below) in a 'public' subnet Edit the route table assigned to the 'private' subnet to have a new route: Destination: 0.0.0.0/0 - This is a special indicator to the route table that works as a 'catch-all' for any network traffic destination not recognized Target: nat-name-of-your-nat-device - Use the AWS console identifer of the NAT device in the 'public' subnet Note this will enable any server or resource in the 'private' subnet to use the NAT device for outbound communication. Types of NAT Devices \u00b6 NAT Devices are not free and the cost to the AWS account depends on the type of device. To assist the decision process, AWS has provided a guide on common types: NAT Gateways - these are AWS-managed instances that are easy to spin-up and have minimal configuration. This is the easiest option for getting started. NAT Instances - these are based on an existing AWS AMI that creates an EC2 instance that you can further customize. AWS even provides a comparison chart to help you decide. Other AWS Services \u00b6 Recall that many AWS services are not accessible directly within a VPC. So if your applications depend on other AWS services such as SNS, SQS, SES, and so forth, a NAT device will be required at additional cost. Advanced Topics \u00b6 There are many, many advanced configurations available with VPC : DNS VPN Connections DHCP VPC Peering But none of these are required to get a basic VPC setup rolling, so they are left as an exercise for the reader. Next Steps \u00b6 I hope you have a solid mental model of the basic building block of AWS VPC and thus can understand the relationships between the myriad of concepts presented in the AWS documentation. With this mental model, I recommend reading carefully through the well-documented VPC Scenarios on the AWS documentation site. How Lambda Works with VPC \u00b6 Now that we've covered the basics with typical resources within a VPC, it's worth discussing how AWS Lambda interacts with a VPC. While it seems to be fairly straightforward, there is a surprise feature with Lambda that bypasses the entire network model. Multiple Subnets allowed \u00b6 When creating a Lambda function, you can assign zero, one, or multiple subnets. If no subnets are specified, then the Lambda function is considered external to all VPCs in the account. The reason for multiple subnets would be mostly for robustness. When a Lambda container is started, it must be assigned an IP address. It will select the IP address from one of the assigned subnets. The exact method for selection is not documented. The Lambda container will run, then release the IP address. But if you have many Lambda containers running, there is a risk of using up all the available IP addresses. In addition, since subnets are assigned a single availability zone (AZ), by associating subnets in a few different AZ, you can increase the chances that your Lambda function will continue to run even if one AZ is having troubles. The downside to assigning multiple subnets is you must ensure the routing rules are identical for both subnets otherwise you could create a situation where Lambda containers may behave differently based on the dynamically assigned subnet. This would be very difficult to troubleshoot. General Behavior and Internet Access \u00b6 When instantiated, Lambda functions are dynamically assigned an Elastic Network Interface (ENI) . This ENI provides the Lambda function the capability to use the VPC subnet network - like someone plugged in a virtual ethernet plug. The ENI conforms to the typical network address for the VPC and subnet to which the Lambda function is assigned. That is, if the Lambda function is instantiated in a public subnet, the ENI will be a public IP; and if the Lambda function is instantiated in a private subnet, the ENI will be a private IP. And if there are other resources like an EC2 instance running in the same subnet, the Lambda function can interact with the EC2 instance just fine. However, there are restrictions placed upon Lambda functions when attempting to access the Internet. No Lambda functions running within a VPC will be able to access the Internet directly. Even if the Lambda function is assigned to a 'public' subnet with access to an Internet Gateway, the Lambda function will not be able to leverage the Internet Gateway. As per AWS Documentation if you want Lambda functions to access the Internet, you must assign those Lambda functions to a 'private' subnet and leverage a NAT device as described above. This includes the scenario when the Lambda functions needs to interact with other AWS services that are considered only available via the Internet. Aside from that, Lambda functions that do not require Internet access can happily operate in any of your VPC subnets. Bypassing your VPC setup \u00b6 It is important to remember that Lambda functions are a separate and distinct AWS service from VPC. VPC merely defines the IP network space in which a Lambda function will operate. The heart of the Lambda service could be considered the ability to be triggered from an event and optionally respond to the event. These events come from various sources and services within the AWS fabric. It can be described as an 'event fabric' consisting of large number of Lambda functions listening for events, processing them, and responding. In fact, this method of communication is completely separate and distinct from network traffic. It has its own security model and retry mechanism -- very much like a point-to-point network. The implications of leveraging this 'event network' is that it can be used to effectively 'tunnel' across separate and distinct VPC and subnets. It takes a little bit of work but consider: Lambda X deployed outside of any VPC in your account Lambda Y deployed in a 'private' subnet within the VPC RDS instance in 'private' subnet within the VPC API Gateway deployed in your account (also outside any VPC) If properly configured the following sequence could happen: API Gateway creates an event for Lambda X Lambda X gets the event, then creates an event for Lambda Y Lambda Y gets the event, then makes a query to the RDS database via traditional network mechanisms Lambda Y returns the information to Lambda X Lambda X returns the information to API Gateway Now this is clearly a contrived example as API Gateway could actually invoke Lambda Y directly. But it is meant to illustrate that with some limitations, there are ways to get around the VPC constructs. A more useful scenario would be to have Lambda Y invoke the Lambda X function to gain access to 'Internet only' AWS services such as SQS without the need for a NAT Device. There are many complications with this strategy: You now have to juggle two different authorization schemes - Lambda and traditional access methods You have doubled the number of Lambda function invocations which could lead to additional charges You have a execution limit on both the number simultaneous of Lambda functions and length of time allowed per invocation You have to create and manage the event chain manually In my opinion, it is important to know this functionality exists, but in almost all cases, it would be more cost effective to leverage one of the NAT Device strategies outlined above. At the time of this writing, the following events can generate events for Lambda functions : Amazon S3 Amazon DynamoDB Amazon Kinesis Streams Amazon Simple Notification Service Amazon Simple Email Service Amazon Cognito AWS CloudFormation Amazon CloudWatch Logs Amazon CloudWatch Events AWS CodeCommit Scheduled Events (powered by Amazon CloudWatch Events) AWS Config Amazon Alexa Amazon Lex Amazon API Gateway Amazon Simple Queue Service Final considerations \u00b6 It takes some planning when planning to deploy a Zappa environment and to determine if VPC is required or necessary. In the next section , we discuss some concrete options for the walkthrough.","title":"Primer on AWS VPC Networking"},{"location":"aws_network_primer/#a-brief-primer-on-aws-vpc-networking-and-how-lambda-functions-relate","text":"Confused on how to create your network environment in AWS? Don't worry - you're in good company. Configuring and using AWS VPC networking is powerful, but complex. This document attempts to create a mental model to help readers understand the concepts and thus allow more reasonable decisions to be made. I find it helpful to draw analogies to traditional network setup within a company to assist building the mental model. If you're already familiar with AWS VPC, you can skip to how AWS Lambda interacts with VPC This document takes the general approach: First, discuss the concepts and talk about how they relate Link to good tutorials on how to create VPCs once the reader has a good understanding We won't go into exacting detail on how to do each step since there are many good tutorials already on the Interwebs.","title":"A Brief Primer on AWS VPC Networking (and how Lambda functions relate)"},{"location":"aws_network_primer/#first-there-is-a-vpc","text":"Back in the bad old days, networks were created by plugging a bunch of network cables into network hardware and were statically configured. In AWS, the amazing thing is that you define the network dynamically by providing parameters to Amazon as a form of Software Defined Networking . So Amazon has hardware in their datacenters but present to users a very dynamic environment is nearly indistinguishable from an old-school network. The first thing most users do is define the overall boundaries of their network using a Virtual Private Cloud or VPC. This is roughly akin to drawing a circle around your infrastructure. The old-school equivalent would be to define your company's internal network space. This network space would allow your various departments to have computers that belong to this space. Old-school companies might have several floors and departments so it would have to be big enough to house all these computers. Additionally, you don't want external hackers have unfettered access to your internal databases and accounting systems so most companies pick Private Network Space to isolate the big bad Internet from the company network. You do this in AWS VPC by defining the IP network space of the total possible IP addresses that could live in the VPC. Now you may not have lots and lots of computers you'll need to put into your VPC, but fortunately you are not charged by Amazon on how many IP addresses you have reserved, so you can err on the side of having a bit of room. The private network ranges available are defined by an Internet 'standard' called RFC 1918 . The private network spaces for IPv4 are: 10.0.0.0 - 10.255.255.255 (10/8 prefix) 172.16.0.0 - 172.31.255.255 (172.16/12 prefix) 192.168.0.0 - 192.168.255.255 (192.168/16 prefix) AWS restricts creation of VPCs with a /16 CIDR mask which limits you to a VPC with 65,536 IP addresses (which is pretty big). This is probably a little excessive for your first VPC, so why not start with something like 10.0.0.0/20 which gives you about 4 thousand IP addresses? Later we'll keep dividing this network space so this is a good start.","title":"First there is a VPC"},{"location":"aws_network_primer/#now-create-your-subnets","text":"Ok, so now we've got a range of IP addresses that we can use and a potential route to the Internet. Using our old-school network analogy, what a typical network engineer would do next is subdivide the network into chunks. And the more technical term of a chunk of the network is a subnet . In physical world, some possible reasons do this are: If a building has multiple floors, maybe one subnet per floor Maybe divide a subnet for each business department (e.g. HR subnet, IT subnet, Software Development subnet) Subnet based on functionality: one subnet for the phone system, one subnet for desktop computers, one subnet for web servers In the VPC world, the only real reasons needed to divide up the VPC is for functionality and security. A very common example would be if you want web application servers in a public subnet and database servers in a private subnet. In this configuration, users on the Internet can point their browsers at your website but cannot directly access your database servers. And you can create a special connection from your public subnet to your private subnet so that only the web application servers can connect to the database servers. In this way, you lessen the chances that bad actors can attack your database by restricting direct access.","title":"Now create your subnets"},{"location":"aws_network_primer/#notes-on-subnet-calculations","text":"There are a lot of complex rules for how big and location of the subnets within the VPC, but there are two important constraints: The size of the subnets must be a power of 2 - which approximately results in the number of IP addresses assigned to the subnet (e.g. 2, 4, 8, 16, 32, 64, 128, 256, etc IP addresses available) The subnets must be contiguous - which means the available IP addresses in the chunk must be sequential By far, the easiest way to visualize this system is to use a tool that handles all the complications for you. I highly recommend the Spiceworks Subnet Calculator","title":"Notes on subnet calculations"},{"location":"aws_network_primer/#but-theres-more","text":"Just a few more notes about subnets created within your VPC. First, each subnet exists in one availability zone within one AWS Region. For your experimentation, this should not be a big deal. But once you have a production system that is designed to be highly-available, then you will probably have to eventually create multiple subnets that are doing the same function (e.g. hosting a database or application servers) to guard against the case when one availability zone is having troubles, your infrastructure still is up. See the AWS documentation for more info on Regions and Availability Zones . Each subnet has a built-in Access Control List (ACL) . This will let you control inbound and outbound network traffic at the TCP/IP level. Thus you can create rules that allow or restrict network traffic that applies to the entire subnet. This is an important distinction from a more robust firewall or security device: regardless of how many servers you may have in your subnet, they all share these rules. So if a particular external IP address is permitted in the ACL, then all servers could generate traffic to that external IP address. If more fine-grained control per resource is necessary, see VPC Security Groups . Lastly, there is a limit of 200 of subnets per VPC imposed by AWS at the time of this writing.","title":"But there's more"},{"location":"aws_network_primer/#hooking-things-up-route-tables","text":"Usually you'll want various subnets to communicate -- and by default, AWS allows all traffic to flow from any subnet to any another. So that's convenient but usually we want a better security posture. AWS VPC uses route tables to figure out how network traffic should be shuffled around. A route table is a configurable object within the AWS console. When you create a new VPC, the AWS system will automatically create a route table for you and assign it to your VPC. A VPC is always assigned to a route table; and that assigned route table is the 'main' route table. But there is no star, no icon, or anything special in the AWS console that this is a 'main' route table -- merely the fact that when you click on the VPC, only one route table will be listed there. And you cannot change a VPC 'main' route table. So this 'main' route table has some special properties. Turns out that each subnet is also assigned a route table. And if you don't explicitly assign a route table on creation of the subnet, it gloms onto whatever the current 'main' route table is. So the 'main' route table is used as a default for all subnets that aren't assigned a specific route table. Thus all the subnets will share a single route table by default unless you take action. By taking action, I mean you can assign a different route table to a subnet.","title":"Hooking things up: route tables"},{"location":"aws_network_primer/#why-do-we-need-multiple-route-tables","text":"The question you may be asking yourself is why do we even need more than one route table? The most common usage is to increase security by specializing the subnets. Since we know all the subnets are really just networks, there is no functional difference until we modify how network traffic flows between the subnets. Back to the example of web app servers and databases. We can put all the web app server instances in Subnet A and the database server instances in Subnet B. But then by restricting the routes so that Subnet B can only talk to Subnet A, we can consider Subnet B as 'private'. Again, there is no sticker, no emjoi, nor icon in the AWS console that designates Subnet B as 'private' except for the fact that we've associated a restricted route table. Conversely, we can allow Internet traffic to go out of Subnet A by assigning a different route table; thereby creating a 'public' subnet in name only.","title":"Why do we need multiple route tables?"},{"location":"aws_network_primer/#talking-to-the-internet","text":"Usually, most applications will need to communicate with the Internet; either taking incoming network connections or retrieving information. In AWS you connect your VPC to the Internet using Internet Gateways . This is a special resource that is assigned to a VPC that allows network traffic to come in and out of your VPC. Internet Gateways are free to AWS users and can be created easily by using the VPC creation wizard or after the fact. An Internet Gateway can only be attached to a single VPC at a time and a VPC can only have up to one IG attached at a time. But VPCs do not have to have Internet Gateways attached. But creating an Internet Gateway and then associating it with a VPC is only the preparation work. In order to actually enable traffic into and out of a subnet, you must have a route associated with the subnet that connects the Internet Gateway. So for the subnet you wish to designate as 'public' you must add a route: Destination: 0.0.0.0/0 - This is a special indicator to the route table that works as a 'catch-all' for any network traffic destination not recognized Target: igw-name-of-your-ig - Use the AWS console identifer of the IG associated with the current VPC And presto! You can now consider any subnets associated with this route table as 'public' subnets. Any EC2 instance that is assigned an Elastic IP can now send and receive traffic from the Internet. Any EC2 instances without an Elastic IP will not be permitted to send and receive traffic.","title":"Talking to the Internet"},{"location":"aws_network_primer/#other-aws-services","text":"Note that many of the AWS services are not associated with any VPC and thus can be considered accessible via Internet-only. For example, if your application living in the VPC needs to connect to the AWS Simple Queue Service (SQS), you will have to enable Internet access via an Internet Gateway as described above. Any AWS service that does not have a VPC endpoint capability is considered Internet only. At the time of this writing, only the following services have VPC endpoints (and thus would not need an Internet Gateway): S3 DynamoDB ElasticSearch In addition, some services like AWS RDS and ElastiCache can be assigned to VPC subnets and thus are natively accessible within a VPC. These services effectively provide fully managed EC2 instances that provide the services and thus can be assigned to one or more VPC subnets.","title":"Other AWS Services"},{"location":"aws_network_primer/#connectivity-from-private-subnets","text":"Often, resources in 'private' subnets will have to communicate to the Internet. Usually, this network traffic is initiated from within the subnet and only return traffic is allowed. If outside network traffic were permitted to initiate communication to 'private' subnet servers, it would expose a potential security risk and thus is not allowed. The mechanism to allow servers and resources within a 'private' subnet to have outbound communication is to have the network traffic sent to a special resource called a NAT device. NAT stands for Network Address Translation and is generally used to hide a number of private servers or resources from any outside network. This NAT device must live in a 'public' subnet with access to the Internet since it acts as a middle-man for the network traffic: the private resources network traffics gets sent from the 'private' subnet to the 'public' subnet and the NAT device passes along the data as if the NAT device was initiating the connection. Enabling a server or resource in a 'private' subnet to communicate to the Internet consists of: Create the NAT Device (more on that below) in a 'public' subnet Edit the route table assigned to the 'private' subnet to have a new route: Destination: 0.0.0.0/0 - This is a special indicator to the route table that works as a 'catch-all' for any network traffic destination not recognized Target: nat-name-of-your-nat-device - Use the AWS console identifer of the NAT device in the 'public' subnet Note this will enable any server or resource in the 'private' subnet to use the NAT device for outbound communication.","title":"Connectivity from private subnets"},{"location":"aws_network_primer/#types-of-nat-devices","text":"NAT Devices are not free and the cost to the AWS account depends on the type of device. To assist the decision process, AWS has provided a guide on common types: NAT Gateways - these are AWS-managed instances that are easy to spin-up and have minimal configuration. This is the easiest option for getting started. NAT Instances - these are based on an existing AWS AMI that creates an EC2 instance that you can further customize. AWS even provides a comparison chart to help you decide.","title":"Types of NAT Devices"},{"location":"aws_network_primer/#other-aws-services_1","text":"Recall that many AWS services are not accessible directly within a VPC. So if your applications depend on other AWS services such as SNS, SQS, SES, and so forth, a NAT device will be required at additional cost.","title":"Other AWS Services"},{"location":"aws_network_primer/#advanced-topics","text":"There are many, many advanced configurations available with VPC : DNS VPN Connections DHCP VPC Peering But none of these are required to get a basic VPC setup rolling, so they are left as an exercise for the reader.","title":"Advanced Topics"},{"location":"aws_network_primer/#next-steps","text":"I hope you have a solid mental model of the basic building block of AWS VPC and thus can understand the relationships between the myriad of concepts presented in the AWS documentation. With this mental model, I recommend reading carefully through the well-documented VPC Scenarios on the AWS documentation site.","title":"Next Steps"},{"location":"aws_network_primer/#how-lambda-works-with-vpc","text":"Now that we've covered the basics with typical resources within a VPC, it's worth discussing how AWS Lambda interacts with a VPC. While it seems to be fairly straightforward, there is a surprise feature with Lambda that bypasses the entire network model.","title":"How Lambda Works with VPC"},{"location":"aws_network_primer/#multiple-subnets-allowed","text":"When creating a Lambda function, you can assign zero, one, or multiple subnets. If no subnets are specified, then the Lambda function is considered external to all VPCs in the account. The reason for multiple subnets would be mostly for robustness. When a Lambda container is started, it must be assigned an IP address. It will select the IP address from one of the assigned subnets. The exact method for selection is not documented. The Lambda container will run, then release the IP address. But if you have many Lambda containers running, there is a risk of using up all the available IP addresses. In addition, since subnets are assigned a single availability zone (AZ), by associating subnets in a few different AZ, you can increase the chances that your Lambda function will continue to run even if one AZ is having troubles. The downside to assigning multiple subnets is you must ensure the routing rules are identical for both subnets otherwise you could create a situation where Lambda containers may behave differently based on the dynamically assigned subnet. This would be very difficult to troubleshoot.","title":"Multiple Subnets allowed"},{"location":"aws_network_primer/#general-behavior-and-internet-access","text":"When instantiated, Lambda functions are dynamically assigned an Elastic Network Interface (ENI) . This ENI provides the Lambda function the capability to use the VPC subnet network - like someone plugged in a virtual ethernet plug. The ENI conforms to the typical network address for the VPC and subnet to which the Lambda function is assigned. That is, if the Lambda function is instantiated in a public subnet, the ENI will be a public IP; and if the Lambda function is instantiated in a private subnet, the ENI will be a private IP. And if there are other resources like an EC2 instance running in the same subnet, the Lambda function can interact with the EC2 instance just fine. However, there are restrictions placed upon Lambda functions when attempting to access the Internet. No Lambda functions running within a VPC will be able to access the Internet directly. Even if the Lambda function is assigned to a 'public' subnet with access to an Internet Gateway, the Lambda function will not be able to leverage the Internet Gateway. As per AWS Documentation if you want Lambda functions to access the Internet, you must assign those Lambda functions to a 'private' subnet and leverage a NAT device as described above. This includes the scenario when the Lambda functions needs to interact with other AWS services that are considered only available via the Internet. Aside from that, Lambda functions that do not require Internet access can happily operate in any of your VPC subnets.","title":"General Behavior and Internet Access"},{"location":"aws_network_primer/#bypassing-your-vpc-setup","text":"It is important to remember that Lambda functions are a separate and distinct AWS service from VPC. VPC merely defines the IP network space in which a Lambda function will operate. The heart of the Lambda service could be considered the ability to be triggered from an event and optionally respond to the event. These events come from various sources and services within the AWS fabric. It can be described as an 'event fabric' consisting of large number of Lambda functions listening for events, processing them, and responding. In fact, this method of communication is completely separate and distinct from network traffic. It has its own security model and retry mechanism -- very much like a point-to-point network. The implications of leveraging this 'event network' is that it can be used to effectively 'tunnel' across separate and distinct VPC and subnets. It takes a little bit of work but consider: Lambda X deployed outside of any VPC in your account Lambda Y deployed in a 'private' subnet within the VPC RDS instance in 'private' subnet within the VPC API Gateway deployed in your account (also outside any VPC) If properly configured the following sequence could happen: API Gateway creates an event for Lambda X Lambda X gets the event, then creates an event for Lambda Y Lambda Y gets the event, then makes a query to the RDS database via traditional network mechanisms Lambda Y returns the information to Lambda X Lambda X returns the information to API Gateway Now this is clearly a contrived example as API Gateway could actually invoke Lambda Y directly. But it is meant to illustrate that with some limitations, there are ways to get around the VPC constructs. A more useful scenario would be to have Lambda Y invoke the Lambda X function to gain access to 'Internet only' AWS services such as SQS without the need for a NAT Device. There are many complications with this strategy: You now have to juggle two different authorization schemes - Lambda and traditional access methods You have doubled the number of Lambda function invocations which could lead to additional charges You have a execution limit on both the number simultaneous of Lambda functions and length of time allowed per invocation You have to create and manage the event chain manually In my opinion, it is important to know this functionality exists, but in almost all cases, it would be more cost effective to leverage one of the NAT Device strategies outlined above. At the time of this writing, the following events can generate events for Lambda functions : Amazon S3 Amazon DynamoDB Amazon Kinesis Streams Amazon Simple Notification Service Amazon Simple Email Service Amazon Cognito AWS CloudFormation Amazon CloudWatch Logs Amazon CloudWatch Events AWS CodeCommit Scheduled Events (powered by Amazon CloudWatch Events) AWS Config Amazon Alexa Amazon Lex Amazon API Gateway Amazon Simple Queue Service","title":"Bypassing your VPC setup"},{"location":"aws_network_primer/#final-considerations","text":"It takes some planning when planning to deploy a Zappa environment and to determine if VPC is required or necessary. In the next section , we discuss some concrete options for the walkthrough.","title":"Final considerations"},{"location":"aws_route53/","text":"Working with Route53 \u00b6 This page lists various activites that may be necessary to perform when leveraging Zappa Create a Hosted Zone in Route53 \u00b6 Navigate to the Route53 console and click Create a Hosted Zone In the Domain Name field, put only the bare or apex form of the domain name. This should be done regardless of the subdomain you wish to host. For our example we would enter: Domain Name: zappaguide.com Type: Public Hosted zone The console should show you a number of DNS records that you must provide to your Registrar Once you enter these values into your Registar it may take some time for the values to propagate depending on the prior settings of the Registrar. In this case your domain name Registrar is someone like GoDaddy or NameCheap. Verify your DNS settings have propagated Using some online tools confirm that for this domain, the DNS Nameservers are correct. If they are not updated, it may take some more time for the information to be propagated. Another useful DNS query tool is https://dns.google.com","title":"Working with Route53"},{"location":"aws_route53/#working-with-route53","text":"This page lists various activites that may be necessary to perform when leveraging Zappa","title":"Working with Route53"},{"location":"aws_route53/#create-a-hosted-zone-in-route53","text":"Navigate to the Route53 console and click Create a Hosted Zone In the Domain Name field, put only the bare or apex form of the domain name. This should be done regardless of the subdomain you wish to host. For our example we would enter: Domain Name: zappaguide.com Type: Public Hosted zone The console should show you a number of DNS records that you must provide to your Registrar Once you enter these values into your Registar it may take some time for the values to propagate depending on the prior settings of the Registrar. In this case your domain name Registrar is someone like GoDaddy or NameCheap. Verify your DNS settings have propagated Using some online tools confirm that for this domain, the DNS Nameservers are correct. If they are not updated, it may take some more time for the information to be propagated. Another useful DNS query tool is https://dns.google.com","title":"Create a Hosted Zone in Route53"},{"location":"setup/","text":"Setup your Environment \u00b6 This section provides guidance to set up a zappa working environment. Why do I need a working environment? \u00b6 While the ultimate goal is to have your Django application hosted in a cloud-based serverless environment, a working environment is needed to: Collect the required packages Build a lambda compatible deployment Upload the deployment Coordinate the various AWS services to enable the cloud-based environment In addition, a working environment assists with development and testing. The caveat is that this working environment will not match exactly the cloud-based deployment. However, the goal is to get a reasonablly close approximation while still balancing ease of use. Baseline packages \u00b6 To ensure baseline expectations are set, all environments will assume the following criteria: Python 3 (according to AWS lambda support ) Django 3.2 or newer Latest version of zappa In addition, zappa requires a virtual environment in which to function. So all approaches below include a virtual environment. Approach #1 - Local Machine \u00b6 You can easily set up your working environment on your local machine. For simple projects, this is very easy to manage and maintain. All you need is Python 3, pip, and virtualenv installed. This works for Windows, MacOS, and Linux machines. Here we setup a working environment named 'zappatest' mkdir zappatest cd zappatest virtualenv ve source ve/bin/activate pip install django zappa And you are done. Warning While this approach is easy to get up and running, the challenge comes along when you require more advanced python packages. For example, once you start connecting to databases, you will need to compile packages such as 'psycopg2' for PostGresSQL. You should consider the implications of installing needed libraries on your local machine. This is approach is not recommended for any type of serious zappa effort. Approach #2 - Docker with zappa (recommended) \u00b6 Sometimes leveraging Docker to create an isolated working environment is a good idea. It takes more work to setup initially, but once you have the foundations, it is quite easy to create multiple working environments and it is easier to share those same environments with other folks on your team. The main goal of using Docker is to create an environment that closely matches the AWS lambda environment. The closer it matches, then there will be less difficult-to-debug problems. We will leverage the work others have done to enable such an environment. First and foremost, the folks from lambci have created github repo called docker-lambda that accurately reflects the lambda environment. It provides: Multiple uses A 'build' image for compilation, package creation, and deployment A 'run' image for testing and execution of your code For the purposes of this walkthrough we will focus only on the 'build' image that provides a very nice interactive working environment for zappa. Further research into how to use the 'run' image is left as an exercise for the reader. Multiple Python version support Python 3.8 ( lambci/lambda:build-python3.8 ) Note that this work was originally inspired from danielwhatmuff/zappa but has been enhanced to illustrate support for Python 3 Inital Setup \u00b6 These steps need to be performed once for a new system Install Docker Pull the zappa docker image from Docker github # For Python 3.6 projects docker pull lambci/lambda:build-python3.8 Create a shortcut that allows AWS credentials to pass through to the docker container If you use environment variables for AWS Credentials then use: alias zappashell = 'docker run -ti -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION -v \"$(pwd):/var/task\" --rm lambci/lambda:build-python3.6 bash' alias zappashell >> ~/.bash_profile Be sure to define the $AWS_DEFAULT_REGION environment variable If you use a credentials file for AWS Credentials then use: alias zappashell = 'docker run -ti -e AWS_PROFILE=$AWS_PROFILE -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm lambci/lambda:build-python3.6 bash' alias zappashell >> ~/.bash_profile Note that you must either define the $AWS_PROFILE environment variable or edit the alias above to be hardcoded to a specific profile. Example of hardcoding the alias: alias zappashell = 'docker run -ti -e AWS_PROFILE=zappa -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm lambci/lambda:build-python3.6 bash' Taking a test drive \u00b6 So let's try this out now. Examples going forward will focus on Python 3.6. To fire up the docker container use: $ cd /your_zappa_project $ zappashell bash-4.2# Next, create the required virtual environment, activate it, and install needed dependencies bash-4.2# virtualenv ve bash-4.2# source ve/bin/activate ( ve ) bash-4.2# pip install -r requirements.txt Since the virtual environment is contained in the current directory, and the current directory is mapped to your local machine, any changes you make will be persisted between Docker container instances. But if you depend on libraries that are installed in the system (essentially anything out of the current directory and virtual environment), they will be lost when the container exits. The solution for this is to create a custom Dockerfile (see below) Finally, I recommend upgrading to the latest zappa project since it changes frequently ( ve ) bash-4.2# pip install --upgrade zappa Warning It is very important that you install and activate the virtualenv only in the docker shell. This will prevent any incompatibilities with the local system environment and the docker environment. At this point, you are ready to start using zappa. Once you are finished, you can simply exit the container. Project Setup \u00b6 Once the steps above are complete, then it is very easy to start a working environment. But generally additional steps are required for package compilation and customizations. Create a Dockerfile \u00b6 Create a local Dockerfile for your project so you can easily modify needed libraries. Generally this can go in the root of your zappa project. FROM lambci/lambda:build-python3.6 LABEL maintainer = \"<your@email.com>\" WORKDIR /var/task # Fancy prompt to remind you are in zappashell RUN echo 'export PS1=\"\\[\\e[36m\\]zappashell>\\[\\e[m\\] \"' >> /root/.bashrc # Additional RUN commands here # RUN yum clean all && \\ # yum -y install <stuff> CMD [ \"bash\" ] Build the docker image \u00b6 $ cd /your_zappa_project $ docker build -t myzappa . This will create a local Docker image on your system. Update your zappashell alias \u00b6 To make sure it points to your new image. Essentially replace lambci/lambda:build-python3.6 with myzappa . Example: alias zappashell = 'docker run -ti -e AWS_PROFILE=zappa -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm myzappa' alias zappashell >> ~/.bash_profile Create the Virtual Environment \u00b6 Create the required virtual environment, activate it, and install needed dependencies $ zappashell zappashell> python -m venv ve zappashell> source ve/bin/activate ( ve ) zappa> pip install -r requirements.txt Since the virtual environment is contained in the current directory, and the current directory is mapped to your local machine, any changes you make will be persisted between Docker container instances. But if you depend on libraries that are installed in the system (essentially anything out of the current directory and virtual environment), they will be lost when the container exits. The solution for this is to add these installations as RUN commands in the Dockerfile. Using your environment \u00b6 Each time you are working on your project, merely fire up the container: $ cd /your_zappa_project $ zappashell zappashell> source ve/bin/activate ( ve ) zappashell> All zappa commands can be used to deploy your project: ( ve ) zappashell> zappa status dev","title":"Setup your Environment"},{"location":"setup/#setup-your-environment","text":"This section provides guidance to set up a zappa working environment.","title":"Setup your Environment"},{"location":"setup/#why-do-i-need-a-working-environment","text":"While the ultimate goal is to have your Django application hosted in a cloud-based serverless environment, a working environment is needed to: Collect the required packages Build a lambda compatible deployment Upload the deployment Coordinate the various AWS services to enable the cloud-based environment In addition, a working environment assists with development and testing. The caveat is that this working environment will not match exactly the cloud-based deployment. However, the goal is to get a reasonablly close approximation while still balancing ease of use.","title":"Why do I need a working environment?"},{"location":"setup/#baseline-packages","text":"To ensure baseline expectations are set, all environments will assume the following criteria: Python 3 (according to AWS lambda support ) Django 3.2 or newer Latest version of zappa In addition, zappa requires a virtual environment in which to function. So all approaches below include a virtual environment.","title":"Baseline packages"},{"location":"setup/#approach-1-local-machine","text":"You can easily set up your working environment on your local machine. For simple projects, this is very easy to manage and maintain. All you need is Python 3, pip, and virtualenv installed. This works for Windows, MacOS, and Linux machines. Here we setup a working environment named 'zappatest' mkdir zappatest cd zappatest virtualenv ve source ve/bin/activate pip install django zappa And you are done. Warning While this approach is easy to get up and running, the challenge comes along when you require more advanced python packages. For example, once you start connecting to databases, you will need to compile packages such as 'psycopg2' for PostGresSQL. You should consider the implications of installing needed libraries on your local machine. This is approach is not recommended for any type of serious zappa effort.","title":"Approach #1 - Local Machine"},{"location":"setup/#approach-2-docker-with-zappa-recommended","text":"Sometimes leveraging Docker to create an isolated working environment is a good idea. It takes more work to setup initially, but once you have the foundations, it is quite easy to create multiple working environments and it is easier to share those same environments with other folks on your team. The main goal of using Docker is to create an environment that closely matches the AWS lambda environment. The closer it matches, then there will be less difficult-to-debug problems. We will leverage the work others have done to enable such an environment. First and foremost, the folks from lambci have created github repo called docker-lambda that accurately reflects the lambda environment. It provides: Multiple uses A 'build' image for compilation, package creation, and deployment A 'run' image for testing and execution of your code For the purposes of this walkthrough we will focus only on the 'build' image that provides a very nice interactive working environment for zappa. Further research into how to use the 'run' image is left as an exercise for the reader. Multiple Python version support Python 3.8 ( lambci/lambda:build-python3.8 ) Note that this work was originally inspired from danielwhatmuff/zappa but has been enhanced to illustrate support for Python 3","title":"Approach #2 - Docker with zappa (recommended)"},{"location":"setup/#inital-setup","text":"These steps need to be performed once for a new system Install Docker Pull the zappa docker image from Docker github # For Python 3.6 projects docker pull lambci/lambda:build-python3.8 Create a shortcut that allows AWS credentials to pass through to the docker container If you use environment variables for AWS Credentials then use: alias zappashell = 'docker run -ti -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION -v \"$(pwd):/var/task\" --rm lambci/lambda:build-python3.6 bash' alias zappashell >> ~/.bash_profile Be sure to define the $AWS_DEFAULT_REGION environment variable If you use a credentials file for AWS Credentials then use: alias zappashell = 'docker run -ti -e AWS_PROFILE=$AWS_PROFILE -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm lambci/lambda:build-python3.6 bash' alias zappashell >> ~/.bash_profile Note that you must either define the $AWS_PROFILE environment variable or edit the alias above to be hardcoded to a specific profile. Example of hardcoding the alias: alias zappashell = 'docker run -ti -e AWS_PROFILE=zappa -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm lambci/lambda:build-python3.6 bash'","title":"Inital Setup"},{"location":"setup/#taking-a-test-drive","text":"So let's try this out now. Examples going forward will focus on Python 3.6. To fire up the docker container use: $ cd /your_zappa_project $ zappashell bash-4.2# Next, create the required virtual environment, activate it, and install needed dependencies bash-4.2# virtualenv ve bash-4.2# source ve/bin/activate ( ve ) bash-4.2# pip install -r requirements.txt Since the virtual environment is contained in the current directory, and the current directory is mapped to your local machine, any changes you make will be persisted between Docker container instances. But if you depend on libraries that are installed in the system (essentially anything out of the current directory and virtual environment), they will be lost when the container exits. The solution for this is to create a custom Dockerfile (see below) Finally, I recommend upgrading to the latest zappa project since it changes frequently ( ve ) bash-4.2# pip install --upgrade zappa Warning It is very important that you install and activate the virtualenv only in the docker shell. This will prevent any incompatibilities with the local system environment and the docker environment. At this point, you are ready to start using zappa. Once you are finished, you can simply exit the container.","title":"Taking a test drive"},{"location":"setup/#project-setup","text":"Once the steps above are complete, then it is very easy to start a working environment. But generally additional steps are required for package compilation and customizations.","title":"Project Setup"},{"location":"setup/#create-a-dockerfile","text":"Create a local Dockerfile for your project so you can easily modify needed libraries. Generally this can go in the root of your zappa project. FROM lambci/lambda:build-python3.6 LABEL maintainer = \"<your@email.com>\" WORKDIR /var/task # Fancy prompt to remind you are in zappashell RUN echo 'export PS1=\"\\[\\e[36m\\]zappashell>\\[\\e[m\\] \"' >> /root/.bashrc # Additional RUN commands here # RUN yum clean all && \\ # yum -y install <stuff> CMD [ \"bash\" ]","title":"Create a Dockerfile"},{"location":"setup/#build-the-docker-image","text":"$ cd /your_zappa_project $ docker build -t myzappa . This will create a local Docker image on your system.","title":"Build the docker image"},{"location":"setup/#update-your-zappashell-alias","text":"To make sure it points to your new image. Essentially replace lambci/lambda:build-python3.6 with myzappa . Example: alias zappashell = 'docker run -ti -e AWS_PROFILE=zappa -v \"$(pwd):/var/task\" -v ~/.aws/:/root/.aws --rm myzappa' alias zappashell >> ~/.bash_profile","title":"Update your zappashell alias"},{"location":"setup/#create-the-virtual-environment","text":"Create the required virtual environment, activate it, and install needed dependencies $ zappashell zappashell> python -m venv ve zappashell> source ve/bin/activate ( ve ) zappa> pip install -r requirements.txt Since the virtual environment is contained in the current directory, and the current directory is mapped to your local machine, any changes you make will be persisted between Docker container instances. But if you depend on libraries that are installed in the system (essentially anything out of the current directory and virtual environment), they will be lost when the container exits. The solution for this is to add these installations as RUN commands in the Dockerfile.","title":"Create the Virtual Environment"},{"location":"setup/#using-your-environment","text":"Each time you are working on your project, merely fire up the container: $ cd /your_zappa_project $ zappashell zappashell> source ve/bin/activate ( ve ) zappashell> All zappa commands can be used to deploy your project: ( ve ) zappashell> zappa status dev","title":"Using your environment"},{"location":"walk_app/","text":"Adapting your Application to Zappa / Lambda \u00b6 If you've done the walkthroughs thus far, they have allowed you to seamlessly get your existing application (or allowed you to create a new one) in AWS Lambda using Zappa . But running code in AWS Lambda is not the same as running code on a dedicated virtual server. This document describes differences in the AWS Lambda environment and outlines many of the possible adaptations you may need to apply to your Application. Minimal disk storage might be persistent \u00b6 When your code runs, whether it was trigged from an HTTP request or other event, the only disk storage available to write files is in /tmp . And that storage is limited to 500MB. Always check the AWS Lambda Limits page because this limitation could change over time. Interestingly, once your code runs and is complete, the AWS Lamda service 'freezes' your container and if trigged again, could 'unfreeze' the container for reuse . What this means from a practical standpoint is that if you need to write out files to /tmp your code could both find files from previous runs and also run out of disk space. The obivous adaptations when writing out files: Do not rely on having files exist between code invocations If the temp files are of significant size, it would be better to clean them up on exit to avoid future code invocations from running out of space Any content uploaded via HTTP (or downloaded/created during invocation) must be persisted elsewhere such as in S3 If you need unique files on disk for each invocation, be sure the space required per invocation multipied by the number of possible invocations is less than 500MB. Some additional use cases: Poor Man's Search Engline \u00b6 You could use the temp space to power file-based tools such as the Whoosh Search Engine by downloading the search index from S3. This may work for small indexes. Passing Environment Variables to your Application \u00b6 There are a number of ways to pass information to your application Environment Variables in Zappa Settings \u00b6 You can include variables in the zappa settings file directly. These variables are easy to set and are included in each deployment. Great for variables that do not change often or are not sensitive (e.g. credentials). { \"dev\": { ... \"environment_variables\": { \"some_key\": \"some_value\" } }, ... } And then you can easily retrieve the information from within your code: import os some_value = os . environ . get ( 'some_key' ) Lambda Environment Variables \u00b6 Your code can pull information from the execution environment by using the built-in AWS Lambda environment variables. There is also a method for adding custom variables via the AWS Console. This method is generally only useful for system-generated variables since custom variables can more easily be configured in zappa settings (see above). First, there are the standard environment variables such as path to code, region, and python path. These values are automatically calculated and driven by AWS. In addition to these system variables, you can set custom environment variables in the AWS Console . So you could add SOME_LAMBDA_KEY in the AWS console and retrieve it in your code: import os some_lamda_key = os . environ . get ( 'SOME_LAMBDA_KEY' ) # or get system values aws_lambda_function_name = os . environ . get ( 'AWS_LAMBDA_FUNCTION_NAME' ) While on the topic of system-generated information, your code can also pull important information from the Python execution context : While a Lambda function is executing, it can interact with the AWS Lambda service to get useful runtime information such as: How much time is remaining before AWS Lambda terminates your Lambda function (timeout is one of the Lambda function configuration properties). The CloudWatch log group and log stream associated with the Lambda function that is executing. The AWS request ID returned to the client that invoked the Lambda function. You can use the request ID for any follow up inquiry with AWS support. If the Lambda function is invoked through AWS Mobile SDK, you can learn more about the mobile application calling the Lambda function.","title":"Application Adaptations"},{"location":"walk_app/#adapting-your-application-to-zappa-lambda","text":"If you've done the walkthroughs thus far, they have allowed you to seamlessly get your existing application (or allowed you to create a new one) in AWS Lambda using Zappa . But running code in AWS Lambda is not the same as running code on a dedicated virtual server. This document describes differences in the AWS Lambda environment and outlines many of the possible adaptations you may need to apply to your Application.","title":"Adapting your Application to Zappa / Lambda"},{"location":"walk_app/#minimal-disk-storage-might-be-persistent","text":"When your code runs, whether it was trigged from an HTTP request or other event, the only disk storage available to write files is in /tmp . And that storage is limited to 500MB. Always check the AWS Lambda Limits page because this limitation could change over time. Interestingly, once your code runs and is complete, the AWS Lamda service 'freezes' your container and if trigged again, could 'unfreeze' the container for reuse . What this means from a practical standpoint is that if you need to write out files to /tmp your code could both find files from previous runs and also run out of disk space. The obivous adaptations when writing out files: Do not rely on having files exist between code invocations If the temp files are of significant size, it would be better to clean them up on exit to avoid future code invocations from running out of space Any content uploaded via HTTP (or downloaded/created during invocation) must be persisted elsewhere such as in S3 If you need unique files on disk for each invocation, be sure the space required per invocation multipied by the number of possible invocations is less than 500MB. Some additional use cases:","title":"Minimal disk storage might be persistent"},{"location":"walk_app/#poor-mans-search-engline","text":"You could use the temp space to power file-based tools such as the Whoosh Search Engine by downloading the search index from S3. This may work for small indexes.","title":"Poor Man's Search Engline"},{"location":"walk_app/#passing-environment-variables-to-your-application","text":"There are a number of ways to pass information to your application","title":"Passing Environment Variables to your Application"},{"location":"walk_app/#environment-variables-in-zappa-settings","text":"You can include variables in the zappa settings file directly. These variables are easy to set and are included in each deployment. Great for variables that do not change often or are not sensitive (e.g. credentials). { \"dev\": { ... \"environment_variables\": { \"some_key\": \"some_value\" } }, ... } And then you can easily retrieve the information from within your code: import os some_value = os . environ . get ( 'some_key' )","title":"Environment Variables in Zappa Settings"},{"location":"walk_app/#lambda-environment-variables","text":"Your code can pull information from the execution environment by using the built-in AWS Lambda environment variables. There is also a method for adding custom variables via the AWS Console. This method is generally only useful for system-generated variables since custom variables can more easily be configured in zappa settings (see above). First, there are the standard environment variables such as path to code, region, and python path. These values are automatically calculated and driven by AWS. In addition to these system variables, you can set custom environment variables in the AWS Console . So you could add SOME_LAMBDA_KEY in the AWS console and retrieve it in your code: import os some_lamda_key = os . environ . get ( 'SOME_LAMBDA_KEY' ) # or get system values aws_lambda_function_name = os . environ . get ( 'AWS_LAMBDA_FUNCTION_NAME' ) While on the topic of system-generated information, your code can also pull important information from the Python execution context : While a Lambda function is executing, it can interact with the AWS Lambda service to get useful runtime information such as: How much time is remaining before AWS Lambda terminates your Lambda function (timeout is one of the Lambda function configuration properties). The CloudWatch log group and log stream associated with the Lambda function that is executing. The AWS request ID returned to the client that invoked the Lambda function. You can use the request ID for any follow up inquiry with AWS support. If the Lambda function is invoked through AWS Mobile SDK, you can learn more about the mobile application calling the Lambda function.","title":"Lambda Environment Variables"},{"location":"walk_core/","text":"Core Django Setup \u00b6 This section documents setting up a Django project with only core Python functionality responding to HTTP calls. The value of this core walkthrough could be to power an API driven compute engine or a event-driven data processing tool without the need to provide a UI. Expectations and Goals \u00b6 After going through this section the following will work: URL Routes in your Django projects Views can produce html / json / data output Management Commands What will not work (yet - see other walkthroughs for this functionality) Static Files will not be served (More on that here ) There is no database connection available (not even SQLite) Custom domain names (More on that here ) Setup AWS Account Credentials \u00b6 Make sure you setup access to your AWS account from your local command line. See: Setup Local Account Credentials Create local environment \u00b6 See Setup your Environment Create very basic Django project \u00b6 For the purposes of this walkthrough we are taking the most basic Django project. From within your project working directory type the following. We are creating a fictional Django project called 'frankie' django-admin startproject frankie . Testing the basic Django project \u00b6 At this point if you run python manage.py runserver And visit http://127.0.0.1:8000 with your browser you should see the standard Django 'It Worked!' page Now quit the server using Control-C. You should be back at the console prompt Setup Zappa \u00b6 zappa init You will encounter a series of prompts: Name of environment - just accept the default 'dev' S3 bucket for deployments. If the bucket does not exist, zappa will create it for you. You can use an existing bucket name if you'd like. Note that this bucket just holds the zappa package temporarily while it is being transferred to AWS lambda. The zappa package is then removed after deployment. For the purposes of the walkthrough we are using zappatest-code Zappa should automatically find the correct Django settings file so accept the default Say 'no' to deploying globally If everything looks ok, then accept the info Here's a transcript of what you should see: (ve) $ zappa init \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2550\u2550\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d Welcome to Zappa! Zappa is a system for running server-less Python web applications on AWS Lambda and AWS API Gateway. This `init` command will help you create and configure your new Zappa deployment. Let's get started! Your Zappa configuration can support multiple production environments, like 'dev', 'staging', and 'production'. What do you want to call this environment (default 'dev'): Your Zappa deployments will need to be uploaded to a private S3 bucket. If you don't have a bucket yet, we'll create one for you too. What do you want call your bucket? (default 'zappa-v20ssav8g'): zappatest-code It looks like this is a Django application! What is the module path to your project's Django settings? We discovered: frankie.settings Where are your project's settings? (default 'frankie.settings'): You can optionally deploy to all available regions in order to provide fast global service. If you are using Zappa for the first time, you probably don't want to do this! Would you like to deploy this application to globally? (default 'n') [y/n/(p)rimary]: n Okay, here's your zappa_settings.js: { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\" } } Does this look okay? (default 'y') [y/n]: y Done! Now you can deploy your Zappa application by executing: $ zappa deploy dev After that, you can update your application code with: $ zappa update dev To learn more, check out our project page on GitHub here: https://github.com/zappa/Zappa and stop by our Slack channel here: http://bit.do/zappa Enjoy!, ~ Team Zappa! (ve) $ Testing the Zappa Setup \u00b6 So now if we run zappa deploy dev But unfortunately we encounter an error: (ve) $ zappa deploy dev Calling deploy for environment dev.. Warning! AWS Lambda may not be available in this AWS Region! Warning! AWS API Gateway may not be available in this AWS Region! Oh no! An error occurred! :( ============== Traceback (most recent call last): [boring callback removed] NoRegionError: You must specify a region. ============== Need help? Found a bug? Let us know! :D File bug reports on GitHub here: https://github.com/zappa/Zappa And join our Slack channel here: https://slack.zappa.io Love!, ~ Team Zappa! (ve) $ Aw man, the error NoRegionError: You must specify a region. is holding us back. Zappa is complaining that no AWS region is specified. So we need to specify a region. In this walkthrough we are leveraging us-east-1 which corresponds to the same region we used above for the S3 bucket. You have options: Specify a default region using environment variables Again, the drawback here is this must be set for every console export AWS_DEFAULT_REGION=us-east-1 Add default region in your ~/.aws/credentials file Better but this will affect all AWS scripts and programs on your machine. [default] aws_access_key_id = your_access_key_id aws_secret_access_key = your_secret_access_key region=us-east-1 Edit the zappa_settings.json file to have an AWS region. Probably best option because now the zappa configuration has minimal dependencies on external user environment. { \"dev\": { \"aws_region\": \"us-east-1\", \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\" } } Don't forget to put commas in the proper place - JSON is fiddly! Deploy your project using Zappa \u00b6 Now it's easy to do the initial deployment zappa deploy dev Zappa will automatically create an AWS API gateway that will route HTTP requests to your lambda Django project. You should see something like: (ve) $ zappa deploy dev Calling deploy for environment dev.. Downloading and installing dependencies.. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:07<00:00, 3.91pkg/s] Packaging project as zip.. Uploading zappatest-dev-1482425936.zip (13.1MiB).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13.8M/13.8M [00:25<00:00, 603KB/s] Scheduling.. Scheduled zappatest-dev-zappa-keep-warm-handler.keep_warm_callback! Uploading zappatest-dev-template-1482425980.json (1.5KiB).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.58K/1.58K [00:00<00:00, 2.08KB/s] Waiting for stack zappatest-dev to create (this can take a bit).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:18<00:00, 4.69s/res] Deploying API Gateway.. Deployment complete!: https://x6kb437rh.execute-api.us-east-1.amazonaws.com/dev Brilliant! We should be able to use a browser to visit the URL provided at the end of the script. Once we do, however, we get: DisallowedHost at / Invalid HTTP_HOST header: 'x6kb437rh.execute-api.us-east-1.amazonaws.com'. You may need to add x6kb437rh.execute-api.us-east-1.amazonaws.com' to ALLOWED_HOSTS. The built-in Django security settings are kicking in and preventing bad stuff from happening. So we need to modify our Django settings file to accommodate the default hostname that AWS API Gateway uses . Note that the AWS region is part of the hostname and thus should match your selected region. Now edit frankie/settings.py and change ALLOWED_HOSTS to; ALLOWED_HOSTS = [ '127.0.0.1', 'x6kb437rh.execute-api.us-east-1.amazonaws.com', ] As an aside, for best security practices, put the full domain of the API Gateway here. Less secure would be to use just .execute-api.us-east-1.amazonaws.com . Once done, we can again deploy to AWS Lambda. But this time, since we've already pushed the initial deploy, we use the update action on the zappa command line. zappa update dev After this completes, you should be able to see your Django site in action. Note that you will actually get a Page not found (404) response. This indicates that your Django site is functional and working. How is this functional? \u00b6 Wait, what? A 404 page is functional? Well yes, it is. The Lambda function is working fine. A whole series of AWS systems are working in concert to load your python Django code and running the view. Because we've cut to the bare minimum Django project, there is no application ready to handle the url paths. The only thing we see is the admin application. So from here we are ready to start working on views and providing data. However, if you wish to host a website with static files and databases, continue onward to the subsequent walkthroughs: Hosting Static Files Using a Database Why is the URL path appended with 'dev'? \u00b6 Astute readers will notice that the url in the image shown above indeed has the root domain with the suffix of 'dev' which happens to be the name of the zappa environment. Indeed, the url domain is based on the generated API Gateway and the path of the URL is the 'Stage Name' of the API Gateway - it matches the name of the Zappa environment you chose above. https://bnu0zcwezd.execute-api.us-east-1.amazonaws.com/dev/ ^^^^^^^^^^^^^^^^^^^^^^ ^^^ Auto Generated API Gateway Your Zappa Environment While this url may be considered functional, most would regard it as extremely unfriendly to users. To improve this and use your own custom domain name see the section on using a Custom Domain . Checking up on the deployment \u00b6 If, at any time, you would like to get information on the deployment, the command to run is zappa status dev And you will get a plethora of data about your deployment: Lambda Versions: 2 Lambda Name: zappatest2-dev Lambda ARN: arn:aws:lambda:us-east-1:738351236015:function:zappatest2-dev Lambda Role ARN: arn:aws:iam::738351236015:role/ZappaLambdaExecution Lambda Handler: handler.lambda_handler Lambda Code Size: 11919234 Lambda Version: $LATEST Lambda Last Modified: 2017-04-02T12:56:32.663+0000 Lambda Memory Size: 512 Lambda Timeout: 30 Lambda Runtime: python2.7 Lambda VPC ID: None Invocations (24h): 6 Errors (24h): 0 Error Rate (24h): 0.00% API Gateway URL: https://i1mf39942k.execute-api.us-east-1.amazonaws.com/dev Domain URL: None Supplied Num. Event Rules: 1 Event Rule ARN: arn:aws:events:us-east-1:1111111111:rule/zappatest2-dev-zappa-keep-warm-handler.keep_warm_callback Event Rule Name: zappatest2-dev-zappa-keep-warm-handler.keep_warm_callback Event Rule State: Enabled Event Rule Schedule: rate(4 minutes) It includes the API Gateway URL which is important in case you ever forget the URL","title":"Core Django Setup"},{"location":"walk_core/#core-django-setup","text":"This section documents setting up a Django project with only core Python functionality responding to HTTP calls. The value of this core walkthrough could be to power an API driven compute engine or a event-driven data processing tool without the need to provide a UI.","title":"Core Django Setup"},{"location":"walk_core/#expectations-and-goals","text":"After going through this section the following will work: URL Routes in your Django projects Views can produce html / json / data output Management Commands What will not work (yet - see other walkthroughs for this functionality) Static Files will not be served (More on that here ) There is no database connection available (not even SQLite) Custom domain names (More on that here )","title":"Expectations and Goals"},{"location":"walk_core/#setup-aws-account-credentials","text":"Make sure you setup access to your AWS account from your local command line. See: Setup Local Account Credentials","title":"Setup AWS Account Credentials"},{"location":"walk_core/#create-local-environment","text":"See Setup your Environment","title":"Create local environment"},{"location":"walk_core/#create-very-basic-django-project","text":"For the purposes of this walkthrough we are taking the most basic Django project. From within your project working directory type the following. We are creating a fictional Django project called 'frankie' django-admin startproject frankie .","title":"Create very basic Django project"},{"location":"walk_core/#testing-the-basic-django-project","text":"At this point if you run python manage.py runserver And visit http://127.0.0.1:8000 with your browser you should see the standard Django 'It Worked!' page Now quit the server using Control-C. You should be back at the console prompt","title":"Testing the basic Django project"},{"location":"walk_core/#setup-zappa","text":"zappa init You will encounter a series of prompts: Name of environment - just accept the default 'dev' S3 bucket for deployments. If the bucket does not exist, zappa will create it for you. You can use an existing bucket name if you'd like. Note that this bucket just holds the zappa package temporarily while it is being transferred to AWS lambda. The zappa package is then removed after deployment. For the purposes of the walkthrough we are using zappatest-code Zappa should automatically find the correct Django settings file so accept the default Say 'no' to deploying globally If everything looks ok, then accept the info Here's a transcript of what you should see: (ve) $ zappa init \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2550\u2550\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d Welcome to Zappa! Zappa is a system for running server-less Python web applications on AWS Lambda and AWS API Gateway. This `init` command will help you create and configure your new Zappa deployment. Let's get started! Your Zappa configuration can support multiple production environments, like 'dev', 'staging', and 'production'. What do you want to call this environment (default 'dev'): Your Zappa deployments will need to be uploaded to a private S3 bucket. If you don't have a bucket yet, we'll create one for you too. What do you want call your bucket? (default 'zappa-v20ssav8g'): zappatest-code It looks like this is a Django application! What is the module path to your project's Django settings? We discovered: frankie.settings Where are your project's settings? (default 'frankie.settings'): You can optionally deploy to all available regions in order to provide fast global service. If you are using Zappa for the first time, you probably don't want to do this! Would you like to deploy this application to globally? (default 'n') [y/n/(p)rimary]: n Okay, here's your zappa_settings.js: { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\" } } Does this look okay? (default 'y') [y/n]: y Done! Now you can deploy your Zappa application by executing: $ zappa deploy dev After that, you can update your application code with: $ zappa update dev To learn more, check out our project page on GitHub here: https://github.com/zappa/Zappa and stop by our Slack channel here: http://bit.do/zappa Enjoy!, ~ Team Zappa! (ve) $","title":"Setup Zappa"},{"location":"walk_core/#testing-the-zappa-setup","text":"So now if we run zappa deploy dev But unfortunately we encounter an error: (ve) $ zappa deploy dev Calling deploy for environment dev.. Warning! AWS Lambda may not be available in this AWS Region! Warning! AWS API Gateway may not be available in this AWS Region! Oh no! An error occurred! :( ============== Traceback (most recent call last): [boring callback removed] NoRegionError: You must specify a region. ============== Need help? Found a bug? Let us know! :D File bug reports on GitHub here: https://github.com/zappa/Zappa And join our Slack channel here: https://slack.zappa.io Love!, ~ Team Zappa! (ve) $ Aw man, the error NoRegionError: You must specify a region. is holding us back. Zappa is complaining that no AWS region is specified. So we need to specify a region. In this walkthrough we are leveraging us-east-1 which corresponds to the same region we used above for the S3 bucket. You have options: Specify a default region using environment variables Again, the drawback here is this must be set for every console export AWS_DEFAULT_REGION=us-east-1 Add default region in your ~/.aws/credentials file Better but this will affect all AWS scripts and programs on your machine. [default] aws_access_key_id = your_access_key_id aws_secret_access_key = your_secret_access_key region=us-east-1 Edit the zappa_settings.json file to have an AWS region. Probably best option because now the zappa configuration has minimal dependencies on external user environment. { \"dev\": { \"aws_region\": \"us-east-1\", \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\" } } Don't forget to put commas in the proper place - JSON is fiddly!","title":"Testing the Zappa Setup"},{"location":"walk_core/#deploy-your-project-using-zappa","text":"Now it's easy to do the initial deployment zappa deploy dev Zappa will automatically create an AWS API gateway that will route HTTP requests to your lambda Django project. You should see something like: (ve) $ zappa deploy dev Calling deploy for environment dev.. Downloading and installing dependencies.. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:07<00:00, 3.91pkg/s] Packaging project as zip.. Uploading zappatest-dev-1482425936.zip (13.1MiB).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13.8M/13.8M [00:25<00:00, 603KB/s] Scheduling.. Scheduled zappatest-dev-zappa-keep-warm-handler.keep_warm_callback! Uploading zappatest-dev-template-1482425980.json (1.5KiB).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.58K/1.58K [00:00<00:00, 2.08KB/s] Waiting for stack zappatest-dev to create (this can take a bit).. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:18<00:00, 4.69s/res] Deploying API Gateway.. Deployment complete!: https://x6kb437rh.execute-api.us-east-1.amazonaws.com/dev Brilliant! We should be able to use a browser to visit the URL provided at the end of the script. Once we do, however, we get: DisallowedHost at / Invalid HTTP_HOST header: 'x6kb437rh.execute-api.us-east-1.amazonaws.com'. You may need to add x6kb437rh.execute-api.us-east-1.amazonaws.com' to ALLOWED_HOSTS. The built-in Django security settings are kicking in and preventing bad stuff from happening. So we need to modify our Django settings file to accommodate the default hostname that AWS API Gateway uses . Note that the AWS region is part of the hostname and thus should match your selected region. Now edit frankie/settings.py and change ALLOWED_HOSTS to; ALLOWED_HOSTS = [ '127.0.0.1', 'x6kb437rh.execute-api.us-east-1.amazonaws.com', ] As an aside, for best security practices, put the full domain of the API Gateway here. Less secure would be to use just .execute-api.us-east-1.amazonaws.com . Once done, we can again deploy to AWS Lambda. But this time, since we've already pushed the initial deploy, we use the update action on the zappa command line. zappa update dev After this completes, you should be able to see your Django site in action. Note that you will actually get a Page not found (404) response. This indicates that your Django site is functional and working.","title":"Deploy your project using Zappa"},{"location":"walk_core/#how-is-this-functional","text":"Wait, what? A 404 page is functional? Well yes, it is. The Lambda function is working fine. A whole series of AWS systems are working in concert to load your python Django code and running the view. Because we've cut to the bare minimum Django project, there is no application ready to handle the url paths. The only thing we see is the admin application. So from here we are ready to start working on views and providing data. However, if you wish to host a website with static files and databases, continue onward to the subsequent walkthroughs: Hosting Static Files Using a Database","title":"How is this functional?"},{"location":"walk_core/#why-is-the-url-path-appended-with-dev","text":"Astute readers will notice that the url in the image shown above indeed has the root domain with the suffix of 'dev' which happens to be the name of the zappa environment. Indeed, the url domain is based on the generated API Gateway and the path of the URL is the 'Stage Name' of the API Gateway - it matches the name of the Zappa environment you chose above. https://bnu0zcwezd.execute-api.us-east-1.amazonaws.com/dev/ ^^^^^^^^^^^^^^^^^^^^^^ ^^^ Auto Generated API Gateway Your Zappa Environment While this url may be considered functional, most would regard it as extremely unfriendly to users. To improve this and use your own custom domain name see the section on using a Custom Domain .","title":"Why is the URL path appended with 'dev'?"},{"location":"walk_core/#checking-up-on-the-deployment","text":"If, at any time, you would like to get information on the deployment, the command to run is zappa status dev And you will get a plethora of data about your deployment: Lambda Versions: 2 Lambda Name: zappatest2-dev Lambda ARN: arn:aws:lambda:us-east-1:738351236015:function:zappatest2-dev Lambda Role ARN: arn:aws:iam::738351236015:role/ZappaLambdaExecution Lambda Handler: handler.lambda_handler Lambda Code Size: 11919234 Lambda Version: $LATEST Lambda Last Modified: 2017-04-02T12:56:32.663+0000 Lambda Memory Size: 512 Lambda Timeout: 30 Lambda Runtime: python2.7 Lambda VPC ID: None Invocations (24h): 6 Errors (24h): 0 Error Rate (24h): 0.00% API Gateway URL: https://i1mf39942k.execute-api.us-east-1.amazonaws.com/dev Domain URL: None Supplied Num. Event Rules: 1 Event Rule ARN: arn:aws:events:us-east-1:1111111111:rule/zappatest2-dev-zappa-keep-warm-handler.keep_warm_callback Event Rule Name: zappatest2-dev-zappa-keep-warm-handler.keep_warm_callback Event Rule State: Enabled Event Rule Schedule: rate(4 minutes) It includes the API Gateway URL which is important in case you ever forget the URL","title":"Checking up on the deployment"},{"location":"walk_database/","text":"Using a Database \u00b6 This walkthough documents the steps necessary to connect your application to a hosted database. Prerequisites \u00b6 This walkthough requires the Core Django Setup to be completed. Also, it is important to have your network setup properly so check out Adventures in Networking . We will assume you have chosen the VPC pattern: \"VPC with a Public subnet and Private subnet\" But basically you will need the private subnet or subnets which can access the database. Options for Databases \u00b6 Use AWS RDS \u00b6 This is probably the easiest to get up and running. AWS takes care of the messy details of managing the host and provides database-as-a-service (if that's a real thing). In addition, AWS RDS supports mySQL and PostGreSQL, both which are highly compatible with Django. Host Your Own \u00b6 Of course you can be running any type of database on an EC2 instance of your choosing. Usually an EC2 instance will be associated with one subnet, but it is possible to have multiple IP addresses in different subnets for redundancy. Use another DB Service \u00b6 There as some other database services such as DynamoDB. Depending on the capabilities of the service, you may or may not need the subnet information. Provision your RDS Database in AWS \u00b6 We'll just focus on the RDS case for this walkthough. In fact we'll go through the walkthough using PostGreSQL. So zip on over to Creating an RDS Database and set up one. You should record some key information we'll need here: The subnets (there should be at least two) in which we can access the database The endpoint (hostname) of the database and the port The username and password for the root user Tip It's strongly recommended that you create your database at the same time you create the RDS instance because it's very easy. In older versions of the AWS console, you could not do this step. If you forget or choose not to, then you'll need to create your database later. Configure RDS security group \u00b6 By default newly created RDS Security Groups have no inbound access . So you need to make sure your RDS Security group has open TCP connections from your subnets associated with the lambdas. So your inbound rules on the RDS security may look like: Type Protocol Port Range Source All TCP TCP 5432 sg9a9a1dfc We open the whole range associated with the security group because when a lambda container is created, it could take any free address in the subnet range. Summary Data \u00b6 Note that at this point you don't yet have a database installed on your RDS instance. So let's just pick a name we will use for the walkthough. Here is our sample data: Parameter Sample value subnets subnet-f3446aba, subnet-c5b8c79e security group sg9a9a1dfc endpoint zappa-db.crt239fsjdlk.us-east-1.rds.amazonaws.com db username administrator db password this_is_not_a_good_password db name zappadbname Setup your Configuration \u00b6 Edit requirements \u00b6 Note on PostGreSQL: because the psycopg2 library often involves compiling the library, I would suggest using the Docker version of zappa to ensure you have isolation of environments and you don't mess up your local system. Add this to your requirements.txt psycopg2 and then pip install -r requirements.txt Django Settings \u00b6 Add the above settings to your settings.py. This is pretty standard Django db stuff. DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql_psycopg2', 'NAME': 'zappadbname', 'USER': 'administrator', 'PASSWORD': 'this_is_not_a_good_password', 'HOST': 'zappa-db.crt239fsjdlk.us-east-1.rds.amazonaws.com', 'PORT': '5432', } } Zappa Settings \u00b6 Now we add the VPC configuration to our Zappa settings file so that the lambda functions can connect to the database. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] } } } Create your Database \u00b6 Ok, easy so far? Yes! All we had to do up to this point was carefully click a mouse in the AWS console and edit some text files. If you've already used the AWS console to create your database when the RDS instance was created, you may skip this section. However, there are many cases where you may have an existing RDS instance and you'll need to create the database not using the AWS console. You have a few options: Use a database tool or GUI on your local machine via a bastion host Use the AWS command line tool Write some code to setup the database using zappa and Django Option 1 is easy if you have the db tool and the bastion host already setup. Let's explore some of these options: Using AWS command line tool \u00b6 Run the aws command tool with the proper options Setup the Database using zappa \u00b6 A more complex way of doing this is to create a management command that can be run in the zappa environment. Then you can have your Django project itself create the database. Create a management command in your Django Project \u00b6 Follow these steps to create a management command environment (make sure your virtualenv is fired up) cd frankie python manage.py startapp axe cd axe mkdir management cd management touch __init__.py mkdir commands cd commands touch __init__.py Then create a file called create_db.py . Put the following code in the file. This management command will connect to the special admin postgres database and create a new database specified by dbname specified in your Django settings file. from psycopg2 import connect from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT from django.core.management.base import BaseCommand , CommandError from django.conf import settings class Command ( BaseCommand ): help = 'Creates the initial database' def handle ( self , * args , ** options ): self . stdout . write ( self . style . SUCCESS ( 'Starting db creation' )) dbname = settings . DATABASES [ 'default' ][ 'NAME' ] user = settings . DATABASES [ 'default' ][ 'USER' ] password = settings . DATABASES [ 'default' ][ 'PASSWORD' ] host = settings . DATABASES [ 'default' ][ 'HOST' ] con = None con = connect ( dbname = 'postgres' , user = user , host = host , password = password ) con . set_isolation_level ( ISOLATION_LEVEL_AUTOCOMMIT ) cur = con . cursor () cur . execute ( 'CREATE DATABASE ' + dbname ) cur . close () con . close () self . stdout . write ( self . style . SUCCESS ( 'All Done' )) Then register app axe to settings.py and update files in aws using this command: zappa update dev Run the management command \u00b6 zappa manage dev create_db If all goes well, then your database should be created. Info There used to be a github project called zappa-django-utils that had a couple more commands, but it's archived now. Init the Database \u00b6 At this point you should have an empty database ready for your Django application to fill up with schema. If this were a traditional server, you would merely run the migrate command. But you can't because there is no command line. Thus we have to modify them to adjust to the new environment. So create your migrations and push the updated code. python manage.py makemigrations zappa update dev Now you invoke the zappa manage command: zappa manage dev migrate And repeat this process every time you make model changes. Create your Django superuser \u00b6 The Django management commands were meant to be run interactively on a command line on a traditional server. Because there is no command line with lambda, we must do some trickery to get around the input needed for the Django createsuperuser management command. Essentially we will use the raw flag on the invoke command to just run raw python. The following command creates a new superuser named 'admin' with email 'admin@yourdomain.com' and password of 'horse battery stapler' zappa invoke --raw dev \"from django.contrib.auth import get_user_model; User = get_user_model(); User.objects.create_superuser('admin', 'admin@yourdomain.com', 'horse battery stapler')\" Additional superusers can be added via this method or the Django admin console. Test and profit \u00b6 At this point you should be able to log into your Django admin: (http://marcelog.github.io/articles/aws_lambda_internet_vpc.html) [https://www.isc.upenn.edu/accessing-mysql-databases-aws-python-lambda-function] Further Topics \u00b6 Security \u00b6 Notice that we are using the master user credentials for the RDS system. It would be more secure if we created a dedicated user that can only access the relevant database. More information on that can be found here: https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04 You will have to modify your custom Django management command to accommodate creation of a new user. SQLite issues with Python 3 \u00b6 While not a hosted service, SQLite often has a lot of value to the Django developer. There is currently an issue with using Python with SQLite on AWS Lambda - while an old version of SQLite is included with Lambda (3.7.17: see https://cloudbriefly.com/post/exploring-the-aws-lambda-execution-environment/ for more details), the Python runtimes do not include Python's SQLite library and thus Django cannot use its built-in SQLite database backend. Django 2.2 and above \u00b6 The solution recommended by zappa's creator is to use django-s3-sqlite , as these newer versions of Django require a version of SQLite (3.8.3+) newer than Lambda's SQLite 3.7.17 installation. When using django-s3-sqlite , in addition to bundling the _sqlite3.so binary as suggested there is the option of using the pysqlite3-binary package . This package includes a recent version of this binary as a wheel, and requires overriding the existing sqlite3 with pysqlite inside settings.py (credit to defulmere's gist for the idea): import sys sys . modules [ 'sqlite3' ] = __import__ ( 'pysqlite3' ) Additional References \u00b6 For MySQL tips: https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04","title":"Using a Database"},{"location":"walk_database/#using-a-database","text":"This walkthough documents the steps necessary to connect your application to a hosted database.","title":"Using a Database"},{"location":"walk_database/#prerequisites","text":"This walkthough requires the Core Django Setup to be completed. Also, it is important to have your network setup properly so check out Adventures in Networking . We will assume you have chosen the VPC pattern: \"VPC with a Public subnet and Private subnet\" But basically you will need the private subnet or subnets which can access the database.","title":"Prerequisites"},{"location":"walk_database/#options-for-databases","text":"","title":"Options for Databases"},{"location":"walk_database/#use-aws-rds","text":"This is probably the easiest to get up and running. AWS takes care of the messy details of managing the host and provides database-as-a-service (if that's a real thing). In addition, AWS RDS supports mySQL and PostGreSQL, both which are highly compatible with Django.","title":"Use AWS RDS"},{"location":"walk_database/#host-your-own","text":"Of course you can be running any type of database on an EC2 instance of your choosing. Usually an EC2 instance will be associated with one subnet, but it is possible to have multiple IP addresses in different subnets for redundancy.","title":"Host Your Own"},{"location":"walk_database/#use-another-db-service","text":"There as some other database services such as DynamoDB. Depending on the capabilities of the service, you may or may not need the subnet information.","title":"Use another DB Service"},{"location":"walk_database/#provision-your-rds-database-in-aws","text":"We'll just focus on the RDS case for this walkthough. In fact we'll go through the walkthough using PostGreSQL. So zip on over to Creating an RDS Database and set up one. You should record some key information we'll need here: The subnets (there should be at least two) in which we can access the database The endpoint (hostname) of the database and the port The username and password for the root user Tip It's strongly recommended that you create your database at the same time you create the RDS instance because it's very easy. In older versions of the AWS console, you could not do this step. If you forget or choose not to, then you'll need to create your database later.","title":"Provision your RDS Database in AWS"},{"location":"walk_database/#configure-rds-security-group","text":"By default newly created RDS Security Groups have no inbound access . So you need to make sure your RDS Security group has open TCP connections from your subnets associated with the lambdas. So your inbound rules on the RDS security may look like: Type Protocol Port Range Source All TCP TCP 5432 sg9a9a1dfc We open the whole range associated with the security group because when a lambda container is created, it could take any free address in the subnet range.","title":"Configure RDS security group"},{"location":"walk_database/#summary-data","text":"Note that at this point you don't yet have a database installed on your RDS instance. So let's just pick a name we will use for the walkthough. Here is our sample data: Parameter Sample value subnets subnet-f3446aba, subnet-c5b8c79e security group sg9a9a1dfc endpoint zappa-db.crt239fsjdlk.us-east-1.rds.amazonaws.com db username administrator db password this_is_not_a_good_password db name zappadbname","title":"Summary Data"},{"location":"walk_database/#setup-your-configuration","text":"","title":"Setup your Configuration"},{"location":"walk_database/#edit-requirements","text":"Note on PostGreSQL: because the psycopg2 library often involves compiling the library, I would suggest using the Docker version of zappa to ensure you have isolation of environments and you don't mess up your local system. Add this to your requirements.txt psycopg2 and then pip install -r requirements.txt","title":"Edit requirements"},{"location":"walk_database/#django-settings","text":"Add the above settings to your settings.py. This is pretty standard Django db stuff. DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql_psycopg2', 'NAME': 'zappadbname', 'USER': 'administrator', 'PASSWORD': 'this_is_not_a_good_password', 'HOST': 'zappa-db.crt239fsjdlk.us-east-1.rds.amazonaws.com', 'PORT': '5432', } }","title":"Django Settings"},{"location":"walk_database/#zappa-settings","text":"Now we add the VPC configuration to our Zappa settings file so that the lambda functions can connect to the database. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] } } }","title":"Zappa Settings"},{"location":"walk_database/#create-your-database","text":"Ok, easy so far? Yes! All we had to do up to this point was carefully click a mouse in the AWS console and edit some text files. If you've already used the AWS console to create your database when the RDS instance was created, you may skip this section. However, there are many cases where you may have an existing RDS instance and you'll need to create the database not using the AWS console. You have a few options: Use a database tool or GUI on your local machine via a bastion host Use the AWS command line tool Write some code to setup the database using zappa and Django Option 1 is easy if you have the db tool and the bastion host already setup. Let's explore some of these options:","title":"Create your Database"},{"location":"walk_database/#using-aws-command-line-tool","text":"Run the aws command tool with the proper options","title":"Using AWS command line tool"},{"location":"walk_database/#setup-the-database-using-zappa","text":"A more complex way of doing this is to create a management command that can be run in the zappa environment. Then you can have your Django project itself create the database.","title":"Setup the Database using zappa"},{"location":"walk_database/#create-a-management-command-in-your-django-project","text":"Follow these steps to create a management command environment (make sure your virtualenv is fired up) cd frankie python manage.py startapp axe cd axe mkdir management cd management touch __init__.py mkdir commands cd commands touch __init__.py Then create a file called create_db.py . Put the following code in the file. This management command will connect to the special admin postgres database and create a new database specified by dbname specified in your Django settings file. from psycopg2 import connect from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT from django.core.management.base import BaseCommand , CommandError from django.conf import settings class Command ( BaseCommand ): help = 'Creates the initial database' def handle ( self , * args , ** options ): self . stdout . write ( self . style . SUCCESS ( 'Starting db creation' )) dbname = settings . DATABASES [ 'default' ][ 'NAME' ] user = settings . DATABASES [ 'default' ][ 'USER' ] password = settings . DATABASES [ 'default' ][ 'PASSWORD' ] host = settings . DATABASES [ 'default' ][ 'HOST' ] con = None con = connect ( dbname = 'postgres' , user = user , host = host , password = password ) con . set_isolation_level ( ISOLATION_LEVEL_AUTOCOMMIT ) cur = con . cursor () cur . execute ( 'CREATE DATABASE ' + dbname ) cur . close () con . close () self . stdout . write ( self . style . SUCCESS ( 'All Done' )) Then register app axe to settings.py and update files in aws using this command: zappa update dev","title":"Create a management command in your Django Project"},{"location":"walk_database/#run-the-management-command","text":"zappa manage dev create_db If all goes well, then your database should be created. Info There used to be a github project called zappa-django-utils that had a couple more commands, but it's archived now.","title":"Run the management command"},{"location":"walk_database/#init-the-database","text":"At this point you should have an empty database ready for your Django application to fill up with schema. If this were a traditional server, you would merely run the migrate command. But you can't because there is no command line. Thus we have to modify them to adjust to the new environment. So create your migrations and push the updated code. python manage.py makemigrations zappa update dev Now you invoke the zappa manage command: zappa manage dev migrate And repeat this process every time you make model changes.","title":"Init the Database"},{"location":"walk_database/#create-your-django-superuser","text":"The Django management commands were meant to be run interactively on a command line on a traditional server. Because there is no command line with lambda, we must do some trickery to get around the input needed for the Django createsuperuser management command. Essentially we will use the raw flag on the invoke command to just run raw python. The following command creates a new superuser named 'admin' with email 'admin@yourdomain.com' and password of 'horse battery stapler' zappa invoke --raw dev \"from django.contrib.auth import get_user_model; User = get_user_model(); User.objects.create_superuser('admin', 'admin@yourdomain.com', 'horse battery stapler')\" Additional superusers can be added via this method or the Django admin console.","title":"Create your Django superuser"},{"location":"walk_database/#test-and-profit","text":"At this point you should be able to log into your Django admin: (http://marcelog.github.io/articles/aws_lambda_internet_vpc.html) [https://www.isc.upenn.edu/accessing-mysql-databases-aws-python-lambda-function]","title":"Test and profit"},{"location":"walk_database/#further-topics","text":"","title":"Further Topics"},{"location":"walk_database/#security","text":"Notice that we are using the master user credentials for the RDS system. It would be more secure if we created a dedicated user that can only access the relevant database. More information on that can be found here: https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04 You will have to modify your custom Django management command to accommodate creation of a new user.","title":"Security"},{"location":"walk_database/#sqlite-issues-with-python-3","text":"While not a hosted service, SQLite often has a lot of value to the Django developer. There is currently an issue with using Python with SQLite on AWS Lambda - while an old version of SQLite is included with Lambda (3.7.17: see https://cloudbriefly.com/post/exploring-the-aws-lambda-execution-environment/ for more details), the Python runtimes do not include Python's SQLite library and thus Django cannot use its built-in SQLite database backend.","title":"SQLite issues with Python 3"},{"location":"walk_database/#django-22-and-above","text":"The solution recommended by zappa's creator is to use django-s3-sqlite , as these newer versions of Django require a version of SQLite (3.8.3+) newer than Lambda's SQLite 3.7.17 installation. When using django-s3-sqlite , in addition to bundling the _sqlite3.so binary as suggested there is the option of using the pysqlite3-binary package . This package includes a recent version of this binary as a wheel, and requires overriding the existing sqlite3 with pysqlite inside settings.py (credit to defulmere's gist for the idea): import sys sys . modules [ 'sqlite3' ] = __import__ ( 'pysqlite3' )","title":"Django 2.2 and above"},{"location":"walk_database/#additional-references","text":"For MySQL tips: https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04","title":"Additional References"},{"location":"walk_debug/","text":"Not yet written \u00b6 https://docs.aws.amazon.com/lambda/latest/dg/dlq.html","title":"Not yet written"},{"location":"walk_debug/#not-yet-written","text":"https://docs.aws.amazon.com/lambda/latest/dg/dlq.html","title":"Not yet written"},{"location":"walk_domain/","text":"Using a Custom Domain \u00b6 If you've followed the walkthroughs thus far, you've at least created a working Django site using Zappa But the URL provided by Zappa is pretty darn ugly. Not only does it use an apparent random domain name, but the Zappa environment is used as the path. For example: https://bnu0zcwezd.execute-api.us-east-1.amazonaws.com/dev/ ^^^^^^^^^^^^^^^^^^^^^^ ^^^ Auto Generated API Gateway Your Zappa Environment Ideally most sites would be something like: https://www.zappaguide.com/ This is entirely possible with Zappa - so how do we get there? Let's talk about HTTPS \u00b6 Perhaps you're wondering why we are introducting the concept of HTTPS when the topic of this walkthough is using a custom domain. Zappa provides an automated way of creating the necessary custom domain mappings as a part of using encryption. Thus many of the techiques described in this walkthough will ultimately end up with a custom domain along with HTTPS. In an effort to make the process straightforward, we are therefore bundling HTTPS as part of the walkthough. Philosophical arguments for HTTPS are made elsewhere . But with free services like \"Let's Encrypt\" and AWS Certificate Manager (free for API Gateways) there is no additional cost burden to leverage HTTPS certificates. Note that we refer to HTTPS instead of SSL and or TLS where appropriate . As a final note, if you are really opposed to encryption, or need unencrypted traffic for some reason, we will provide a method to accomplish this at the end of the walkthrough. Overview of the process \u00b6 There are a number of services that are involved in this process: Domain Name Registrar - Allows you to purchase and register domain names DNS Providers - Allows you to host things online using that domain name Certificate Authority (CA) - Provides encryption certifications to encrypt traffic for the site Combined with Zappa, these services will all be used in this walkthrough. Note that many companies and organizations can provide these services and some, like Amazon, can provide all three. Ultimately, the AWS API Gateway will be associated with a new, dedicated CloudFront distribution that not only leverages the digital certificate to provide HTTPS, but also hides the Zappa environment path. Finally, a DNS record will point to this new CloudFront Distro to complete the experience for the end user. Registering your Custom Domain \u00b6 First you need a registered domain. It doesn't matter who your domain registrar is as long as you have control over the name server records to point to a DNS provider. Of all the services, this one is the most generic and almost any Registar will do. Let's choose an example domain for this walkthrough: www.zappaguide.com Choices \u00b6 At this point, you have a registered domain name and a working Zappa deployment. There are two options: Use the built-in Zappa commands The Zappa project has a very easy way of associating your custom domain name with your Zappa deployment. For most circumstances, this will meet the needs of most applications. What happens behind the scenes is that Zappa tells the AWS API Gateway to associate a private AWS CloudFront distribution with the Custom Domain along with an HTTPS certificate. This CloudFront distribution cannot be configured, but will faithfully pass along HTTP requests as needed. It's easy to use and gets you up and running quickly. Manage your own CloudFront Distribution The private CloudFront distribution created with the API Gateway is fine, but sometimes you need more control. The alternative is to create your own AWS CloudFront Distribution. By doing this, you still associate a Custom Domain Name with HTTPS, but you unlock the full power of AWS CloudFront. Using the built-in Zappa commands \u00b6 Zappa has some built-in functionality that streamlines the process of associating a Custom Domain Name with your Zappa deployment. Since there are so many service providers, we focus on a couple combinations that work best. Use the chart below to select the scenario that best matches your situation and follow only one set of instructions. DNS Provider CA Notes Instructions Route53 AWS Certificate Manager All AWS combo makes this ridiculous easy see below Route53 Let's Encrypt An option that Zappa has smoothed the way, but may be deprecated in the future see below Other DNS ACM or Let's Encrypt There are more manual steps see below Other DNS Other You got some work to do see below Option 1: Route53 and ACM \u00b6 This option assumes that you will be using AWS Route53 and Amazon Certficate Manager for all functions, except perhaps the domain registration itself. Therefore any domain registrar will work under this option be it NameCheap, GoDaddy, or anyone else. Of course the domain name can be registered with Route53. Step 1.1: Create a Hosted Zone in Route53 \u00b6 If your Registrar is also Route53, skip this step and move on to Step 2. AWS did this for you when you registered the domain. Follow the instructions for creating a hosted zone in Route53 Step 1.2: Create your digital certificate in ACM \u00b6 Follow the instructions for requesting a certificate in the ACM console Be sure to record the ARN for the newly issued certificate. Step 1.3: Edit the Zappa Settings File \u00b6 Now we add the following to our Zappa settings file. These settings prepare Zappa to configure our API gateway properly. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] }, \"certificate_arn\": \"arn:aws:acm:us-east-1:738356466015:certificate/1d066282-ce94-4ad7-a802-2ff87d32b104\", \"domain\": \"www.zappaguide.com\", } } For the certificate_arn use the ARN value obtained in step 2 above. For the domain here we could choose either www.zappaguide.com or zappaguide.com , but not both. In order to handle both, either a redirect must occur or you can setup another CloudFront Distribution manually . Step 1.4: Run Certify \u00b6 This final step triggers your local Zappa environment to reach out to AWS and configure your API Gateway to honor the domain name specified. (ve) $ zappa certify dev Calling certify for environment dev.. Are you sure you want to certify? [y/n] y Certifying domain www.zappaguide.com.. Created a new domain name with supplied certificate. Please note that it can take up to 40 minutes for this domain to be created and propagated through AWS, but it requires no further work on your part. Certificate updated! (ve) $ And that should work fine going forward Note Amazon official documentation states that this step could take up to 40 minutes to initialize the certificate. Note The cloudfront distro associated with the zappa API gateway is hidden from the CF distro tool and is exclusively associated with the API gateway. In addition, you cannot configure any settings on it. Warning This command must be run in the US East (N. Virginia) (us-east-1). See AWS documentation for more details. Option 2: Route53 and Let's Encrypt \u00b6 Warning As of Fall/Winter 2017, there has been discussion by Zappa developers that this option may ultimately be deprecated and removed. Step 2.1: Create a Hosted Zone in Route53 \u00b6 If your Registrar is also Route53, skip this step and move on to Step 2. AWS did this for you when you registered the domain. Follow the instructions for creating a hosted zone in Route53 Step 2.2: Create an AWS RSA Key \u00b6 Zappa will interact automatically with Let's Encrypt on your behalf, but first you must create an RSA key to identify your account to Let's Encrypt. To generate it, simply run: (ve) $ openssl genrsa -out le-account.key 2048 Generating RSA private key, 2048 bit long modulus ...........................................................................................................................+++ ..........+++ e is 65537 (0x10001) (ve) $ Be sure to protect this key because it will enable HTTPS certificates to be generated and you will not be able to update an HTTPS certificate if you lose it. Note Note that this is a 2048b key. It's generally preferred to use a stronger 4096b key, but AWS does not yet support keys larger than 2048b. Step 2.3: Edit the Zappa Settings File \u00b6 Now we add the following to our Zappa settings file. These settings prepare Zappa to configure our API gateway properly. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] }, \"lets_encrypt_key\": \"le-account.key\", // Local path to account key - can also be s3 path \"domain\": \"www.zappaguide.com\", } } Step 2.4: Run Certify \u00b6 This final step triggers your local Zappa environment to reach out to AWS and configure your API Gateway to honor the domain name specified. (ve) $ zappa certify dev Calling certify for environment dev.. Are you sure you want to certify? [y/n] y Certifying domain www.zappaguide.com.. Created a new domain name with supplied certificate. Please note that it can take up to 40 minutes for this domain to be created and propagated through AWS, but it requires no further work on your part. Certificate updated! (ve) $ And that should work fine going forward. Note that Let's Encrypt certificates only last for 3 months so you should ensure you update the certificate before the 3 months expire. Note Amazon official documentation states that this step could take up to 40 minutes to initialize the certificate. Other Service Providers \u00b6 If you choose to use your own DNS provider and/or your own Certificate Authority to create the custom domain names, you will have to perform the manual steps outlined in the official AWS documentation: http://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html#how-to-custom-domains-console In this case, I would recommend against using the built-in Zappa commands because of unexpected side effects. What's the path of least resistance? Given these conditions, you should seriously consider a custom CloudFront Distribution . Managing your own CloudFront Distribution is not a lot of work, there are many benefits, and the available documentation is more abundant and complete. Troubleshooting \u00b6 Using your own domain name can be one of the most frustrating experiences, especially due to the potential for a long delay while AWS is creating/setting up the necessary components. Here we list some of the common errors that you may get when you think everything is working. 403 - Forbidden! \u00b6 Sometimes you may encounter the dreaded '403 - Forbidden message': {\"message\":\"Forbidden\"} Often this happens when the user runs zappa certify but has not completed all the steps or correctly configured the zappa settings file. The best way to handle this is generally to manually remove any partially configured custom domains from the AWS console and then try to run zappa certify again. Follow these steps to remove any partial custom domain remnants. Step 1 - Browse to API Gateway -> Custom Domain \u00b6 Step 2 - Remove the Custom Domain Mapping \u00b6 Step 3 - Re-run zappa certify \u00b6 Django is redirecting to the raw url \u00b6 Another mistake often seen is that when a form is submitted or another HTTP redirect happens, the URL generated is no longer the custom domain, but rather the 'raw' API Gateway URL. If you see this, most often you are missing the domain parameter in the zappa settings file. Manage Your Own CloudFront Distribution \u00b6 As mentioned, sometimes you may run into the limitations of the CloudFront Distro created with API Gateway. Of course this depends on what requirements your project needs in your scenarios. The AWS CloudFront service is marketed as a Content Delivery Network (CDN), traditionally used to serve static content to users. In reality, CloudFront has rich and full-featured set of capabilities to deliver almost any kind of data including dynamic data from a website. Additional functionality when you use your own CloudFront distributions include: Aggregate Static and Dynamic Content - If you are serving static content from S3 or other static services , you can use a custom CloudFront Distro to have a single domain name for your entire website by using multiple origins . This sometimes simplifies technologies that are easier to configure with a single domain policy (e.g. CORS, HTTPS, etc). Also busy sites may get a more cost effective delivery mechanism than serving directly from S3. This is because the CloudFront per byte delivery is lower than directly from S3 and a good caching strategy will allow those assets to be served from CloudFront instead of S3. Extensive cache control - This will let you configure caching timeouts for multiple paths. So if you have a fairly static landing page, the cache timeout could be days or weeks; while the user account page may have cache of seconds or minutes. Advanced caching could include query parameters and/or cookies. While some frameworks like Django have very good cache header controls, other Python frameworks do not. Geo Restrictions - CloudFront has the ability to restrict and/or modify content based on geographic location . Using your own CloudFront Distro enables you to control this feature. Enhanced Security - If your application requires increased security, then you can leverage both AWS Web Application Firewall (WAF) and AWS Shield (Managed DDOS Protection) . But you cannot use these services without creating your own custom CloudFront. Serving Private Content - CloudFront supports the ability to create signed URLs and cookies that allow only authorized end users to access content (e.g. videos, images, etc). Deployment Flexiblity - If your project tends to have a lot of changes and there is a possiblity that you may wish to switch between zappa deployments without significant downtime then you'll want your own CloudFront Distro. Running certify on a new zappa deployment could take up to 40 minutes, and requires the domain and ssl certs, thus causing a service outage if the domain is in use. Having a custom CloudFront Distro allows you to switch the origin path between zappa deployments with only having to consider cache timeouts. Basically if you'd like to leverage some of the powerful features and tools not exposed by default. See the AWS CloudFront documentation for more information. Create a CloudFront Distribution \u00b6 To get started, follow these instructions Some key parameters: Select 'Web' Distribution For Origin Domain Name, use the Zappa distribution domain name (e.g. 'bnu0zcwezd.execute-api.us-east-1.amazonaws.com') For Origin Path, use the Zappa deployment name (e.g. 'dev') For Object Caching: If you'd like to use Django to control the cache, select 'Use Origin Cache Headers' If you'd like to setup static cache timeouts, select 'Customize' Use the Minimum TTL, Maximum TTL, and Default TTL to specify how long (in seconds) to cache objects You can add additional paths as needed Compress Objects Automatically, we recommend True Associate HTTPS certificate \u00b6 Follow these instructions to associate your new distro with a SSL/TLS certificate. Then create additional 'Origins' \u00b6 So now that you have your default origin configured you can add additional ones. And you can point to various url paths in your application to configure the cache timings and other behavoirs like compression and so on.","title":"Custom Domains"},{"location":"walk_domain/#using-a-custom-domain","text":"If you've followed the walkthroughs thus far, you've at least created a working Django site using Zappa But the URL provided by Zappa is pretty darn ugly. Not only does it use an apparent random domain name, but the Zappa environment is used as the path. For example: https://bnu0zcwezd.execute-api.us-east-1.amazonaws.com/dev/ ^^^^^^^^^^^^^^^^^^^^^^ ^^^ Auto Generated API Gateway Your Zappa Environment Ideally most sites would be something like: https://www.zappaguide.com/ This is entirely possible with Zappa - so how do we get there?","title":"Using a Custom Domain"},{"location":"walk_domain/#lets-talk-about-https","text":"Perhaps you're wondering why we are introducting the concept of HTTPS when the topic of this walkthough is using a custom domain. Zappa provides an automated way of creating the necessary custom domain mappings as a part of using encryption. Thus many of the techiques described in this walkthough will ultimately end up with a custom domain along with HTTPS. In an effort to make the process straightforward, we are therefore bundling HTTPS as part of the walkthough. Philosophical arguments for HTTPS are made elsewhere . But with free services like \"Let's Encrypt\" and AWS Certificate Manager (free for API Gateways) there is no additional cost burden to leverage HTTPS certificates. Note that we refer to HTTPS instead of SSL and or TLS where appropriate . As a final note, if you are really opposed to encryption, or need unencrypted traffic for some reason, we will provide a method to accomplish this at the end of the walkthrough.","title":"Let's talk about HTTPS"},{"location":"walk_domain/#overview-of-the-process","text":"There are a number of services that are involved in this process: Domain Name Registrar - Allows you to purchase and register domain names DNS Providers - Allows you to host things online using that domain name Certificate Authority (CA) - Provides encryption certifications to encrypt traffic for the site Combined with Zappa, these services will all be used in this walkthrough. Note that many companies and organizations can provide these services and some, like Amazon, can provide all three. Ultimately, the AWS API Gateway will be associated with a new, dedicated CloudFront distribution that not only leverages the digital certificate to provide HTTPS, but also hides the Zappa environment path. Finally, a DNS record will point to this new CloudFront Distro to complete the experience for the end user.","title":"Overview of the process"},{"location":"walk_domain/#registering-your-custom-domain","text":"First you need a registered domain. It doesn't matter who your domain registrar is as long as you have control over the name server records to point to a DNS provider. Of all the services, this one is the most generic and almost any Registar will do. Let's choose an example domain for this walkthrough: www.zappaguide.com","title":"Registering your Custom Domain"},{"location":"walk_domain/#choices","text":"At this point, you have a registered domain name and a working Zappa deployment. There are two options: Use the built-in Zappa commands The Zappa project has a very easy way of associating your custom domain name with your Zappa deployment. For most circumstances, this will meet the needs of most applications. What happens behind the scenes is that Zappa tells the AWS API Gateway to associate a private AWS CloudFront distribution with the Custom Domain along with an HTTPS certificate. This CloudFront distribution cannot be configured, but will faithfully pass along HTTP requests as needed. It's easy to use and gets you up and running quickly. Manage your own CloudFront Distribution The private CloudFront distribution created with the API Gateway is fine, but sometimes you need more control. The alternative is to create your own AWS CloudFront Distribution. By doing this, you still associate a Custom Domain Name with HTTPS, but you unlock the full power of AWS CloudFront.","title":"Choices"},{"location":"walk_domain/#using-the-built-in-zappa-commands","text":"Zappa has some built-in functionality that streamlines the process of associating a Custom Domain Name with your Zappa deployment. Since there are so many service providers, we focus on a couple combinations that work best. Use the chart below to select the scenario that best matches your situation and follow only one set of instructions. DNS Provider CA Notes Instructions Route53 AWS Certificate Manager All AWS combo makes this ridiculous easy see below Route53 Let's Encrypt An option that Zappa has smoothed the way, but may be deprecated in the future see below Other DNS ACM or Let's Encrypt There are more manual steps see below Other DNS Other You got some work to do see below","title":"Using the built-in Zappa commands"},{"location":"walk_domain/#option-1-route53-and-acm","text":"This option assumes that you will be using AWS Route53 and Amazon Certficate Manager for all functions, except perhaps the domain registration itself. Therefore any domain registrar will work under this option be it NameCheap, GoDaddy, or anyone else. Of course the domain name can be registered with Route53.","title":"Option 1: Route53 and ACM"},{"location":"walk_domain/#step-11-create-a-hosted-zone-in-route53","text":"If your Registrar is also Route53, skip this step and move on to Step 2. AWS did this for you when you registered the domain. Follow the instructions for creating a hosted zone in Route53","title":"Step 1.1: Create a Hosted Zone in Route53"},{"location":"walk_domain/#step-12-create-your-digital-certificate-in-acm","text":"Follow the instructions for requesting a certificate in the ACM console Be sure to record the ARN for the newly issued certificate.","title":"Step 1.2: Create your digital certificate in ACM"},{"location":"walk_domain/#step-13-edit-the-zappa-settings-file","text":"Now we add the following to our Zappa settings file. These settings prepare Zappa to configure our API gateway properly. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] }, \"certificate_arn\": \"arn:aws:acm:us-east-1:738356466015:certificate/1d066282-ce94-4ad7-a802-2ff87d32b104\", \"domain\": \"www.zappaguide.com\", } } For the certificate_arn use the ARN value obtained in step 2 above. For the domain here we could choose either www.zappaguide.com or zappaguide.com , but not both. In order to handle both, either a redirect must occur or you can setup another CloudFront Distribution manually .","title":"Step 1.3: Edit the Zappa Settings File"},{"location":"walk_domain/#step-14-run-certify","text":"This final step triggers your local Zappa environment to reach out to AWS and configure your API Gateway to honor the domain name specified. (ve) $ zappa certify dev Calling certify for environment dev.. Are you sure you want to certify? [y/n] y Certifying domain www.zappaguide.com.. Created a new domain name with supplied certificate. Please note that it can take up to 40 minutes for this domain to be created and propagated through AWS, but it requires no further work on your part. Certificate updated! (ve) $ And that should work fine going forward Note Amazon official documentation states that this step could take up to 40 minutes to initialize the certificate. Note The cloudfront distro associated with the zappa API gateway is hidden from the CF distro tool and is exclusively associated with the API gateway. In addition, you cannot configure any settings on it. Warning This command must be run in the US East (N. Virginia) (us-east-1). See AWS documentation for more details.","title":"Step 1.4: Run Certify"},{"location":"walk_domain/#option-2-route53-and-lets-encrypt","text":"Warning As of Fall/Winter 2017, there has been discussion by Zappa developers that this option may ultimately be deprecated and removed.","title":"Option 2: Route53 and Let's Encrypt"},{"location":"walk_domain/#step-21-create-a-hosted-zone-in-route53","text":"If your Registrar is also Route53, skip this step and move on to Step 2. AWS did this for you when you registered the domain. Follow the instructions for creating a hosted zone in Route53","title":"Step 2.1: Create a Hosted Zone in Route53"},{"location":"walk_domain/#step-22-create-an-aws-rsa-key","text":"Zappa will interact automatically with Let's Encrypt on your behalf, but first you must create an RSA key to identify your account to Let's Encrypt. To generate it, simply run: (ve) $ openssl genrsa -out le-account.key 2048 Generating RSA private key, 2048 bit long modulus ...........................................................................................................................+++ ..........+++ e is 65537 (0x10001) (ve) $ Be sure to protect this key because it will enable HTTPS certificates to be generated and you will not be able to update an HTTPS certificate if you lose it. Note Note that this is a 2048b key. It's generally preferred to use a stronger 4096b key, but AWS does not yet support keys larger than 2048b.","title":"Step 2.2: Create an AWS RSA Key"},{"location":"walk_domain/#step-23-edit-the-zappa-settings-file","text":"Now we add the following to our Zappa settings file. These settings prepare Zappa to configure our API gateway properly. { \"dev\": { \"django_settings\": \"frankie.settings\", \"s3_bucket\": \"zappatest-code\", \"aws_region\": \"us-east-1\", \"vpc_config\" : { \"SubnetIds\": [ \"subnet-f3446aba\",\"subnet-c5b8c79e\" ], // use the private subnet \"SecurityGroupIds\": [ \"sg-9a9a1dfc\" ] }, \"lets_encrypt_key\": \"le-account.key\", // Local path to account key - can also be s3 path \"domain\": \"www.zappaguide.com\", } }","title":"Step 2.3: Edit the Zappa Settings File"},{"location":"walk_domain/#step-24-run-certify","text":"This final step triggers your local Zappa environment to reach out to AWS and configure your API Gateway to honor the domain name specified. (ve) $ zappa certify dev Calling certify for environment dev.. Are you sure you want to certify? [y/n] y Certifying domain www.zappaguide.com.. Created a new domain name with supplied certificate. Please note that it can take up to 40 minutes for this domain to be created and propagated through AWS, but it requires no further work on your part. Certificate updated! (ve) $ And that should work fine going forward. Note that Let's Encrypt certificates only last for 3 months so you should ensure you update the certificate before the 3 months expire. Note Amazon official documentation states that this step could take up to 40 minutes to initialize the certificate.","title":"Step 2.4: Run Certify"},{"location":"walk_domain/#other-service-providers","text":"If you choose to use your own DNS provider and/or your own Certificate Authority to create the custom domain names, you will have to perform the manual steps outlined in the official AWS documentation: http://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html#how-to-custom-domains-console In this case, I would recommend against using the built-in Zappa commands because of unexpected side effects. What's the path of least resistance? Given these conditions, you should seriously consider a custom CloudFront Distribution . Managing your own CloudFront Distribution is not a lot of work, there are many benefits, and the available documentation is more abundant and complete.","title":"Other Service Providers"},{"location":"walk_domain/#troubleshooting","text":"Using your own domain name can be one of the most frustrating experiences, especially due to the potential for a long delay while AWS is creating/setting up the necessary components. Here we list some of the common errors that you may get when you think everything is working.","title":"Troubleshooting"},{"location":"walk_domain/#403-forbidden","text":"Sometimes you may encounter the dreaded '403 - Forbidden message': {\"message\":\"Forbidden\"} Often this happens when the user runs zappa certify but has not completed all the steps or correctly configured the zappa settings file. The best way to handle this is generally to manually remove any partially configured custom domains from the AWS console and then try to run zappa certify again. Follow these steps to remove any partial custom domain remnants.","title":"403 - Forbidden!"},{"location":"walk_domain/#step-1-browse-to-api-gateway-custom-domain","text":"","title":"Step 1 - Browse to API Gateway -&gt; Custom Domain"},{"location":"walk_domain/#step-2-remove-the-custom-domain-mapping","text":"","title":"Step 2 - Remove the Custom Domain Mapping"},{"location":"walk_domain/#step-3-re-run-zappa-certify","text":"","title":"Step 3 - Re-run zappa certify"},{"location":"walk_domain/#django-is-redirecting-to-the-raw-url","text":"Another mistake often seen is that when a form is submitted or another HTTP redirect happens, the URL generated is no longer the custom domain, but rather the 'raw' API Gateway URL. If you see this, most often you are missing the domain parameter in the zappa settings file.","title":"Django is redirecting to the raw url"},{"location":"walk_domain/#manage-your-own-cloudfront-distribution","text":"As mentioned, sometimes you may run into the limitations of the CloudFront Distro created with API Gateway. Of course this depends on what requirements your project needs in your scenarios. The AWS CloudFront service is marketed as a Content Delivery Network (CDN), traditionally used to serve static content to users. In reality, CloudFront has rich and full-featured set of capabilities to deliver almost any kind of data including dynamic data from a website. Additional functionality when you use your own CloudFront distributions include: Aggregate Static and Dynamic Content - If you are serving static content from S3 or other static services , you can use a custom CloudFront Distro to have a single domain name for your entire website by using multiple origins . This sometimes simplifies technologies that are easier to configure with a single domain policy (e.g. CORS, HTTPS, etc). Also busy sites may get a more cost effective delivery mechanism than serving directly from S3. This is because the CloudFront per byte delivery is lower than directly from S3 and a good caching strategy will allow those assets to be served from CloudFront instead of S3. Extensive cache control - This will let you configure caching timeouts for multiple paths. So if you have a fairly static landing page, the cache timeout could be days or weeks; while the user account page may have cache of seconds or minutes. Advanced caching could include query parameters and/or cookies. While some frameworks like Django have very good cache header controls, other Python frameworks do not. Geo Restrictions - CloudFront has the ability to restrict and/or modify content based on geographic location . Using your own CloudFront Distro enables you to control this feature. Enhanced Security - If your application requires increased security, then you can leverage both AWS Web Application Firewall (WAF) and AWS Shield (Managed DDOS Protection) . But you cannot use these services without creating your own custom CloudFront. Serving Private Content - CloudFront supports the ability to create signed URLs and cookies that allow only authorized end users to access content (e.g. videos, images, etc). Deployment Flexiblity - If your project tends to have a lot of changes and there is a possiblity that you may wish to switch between zappa deployments without significant downtime then you'll want your own CloudFront Distro. Running certify on a new zappa deployment could take up to 40 minutes, and requires the domain and ssl certs, thus causing a service outage if the domain is in use. Having a custom CloudFront Distro allows you to switch the origin path between zappa deployments with only having to consider cache timeouts. Basically if you'd like to leverage some of the powerful features and tools not exposed by default. See the AWS CloudFront documentation for more information.","title":"Manage Your Own CloudFront Distribution"},{"location":"walk_domain/#create-a-cloudfront-distribution","text":"To get started, follow these instructions Some key parameters: Select 'Web' Distribution For Origin Domain Name, use the Zappa distribution domain name (e.g. 'bnu0zcwezd.execute-api.us-east-1.amazonaws.com') For Origin Path, use the Zappa deployment name (e.g. 'dev') For Object Caching: If you'd like to use Django to control the cache, select 'Use Origin Cache Headers' If you'd like to setup static cache timeouts, select 'Customize' Use the Minimum TTL, Maximum TTL, and Default TTL to specify how long (in seconds) to cache objects You can add additional paths as needed Compress Objects Automatically, we recommend True","title":"Create a CloudFront Distribution"},{"location":"walk_domain/#associate-https-certificate","text":"Follow these instructions to associate your new distro with a SSL/TLS certificate.","title":"Associate HTTPS certificate"},{"location":"walk_domain/#then-create-additional-origins","text":"So now that you have your default origin configured you can add additional ones. And you can point to various url paths in your application to configure the cache timings and other behavoirs like compression and so on.","title":"Then create additional 'Origins'"},{"location":"walk_media/","text":"Managing Media files (or any other file) \u00b6 So we're talking mostly about getting stuff in/out of S3 Baseline setup http://serverfault.com/questions/578571/accessing-amazon-s3-from-a-private-vpc-subnet http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints-s3.html?shortFooter=true http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html#vpc-endpoints-limitations","title":"Managing Media files (or any other file)"},{"location":"walk_media/#managing-media-files-or-any-other-file","text":"So we're talking mostly about getting stuff in/out of S3 Baseline setup http://serverfault.com/questions/578571/accessing-amazon-s3-from-a-private-vpc-subnet http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints-s3.html?shortFooter=true http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html#vpc-endpoints-limitations","title":"Managing Media files (or any other file)"},{"location":"walk_scheduling/","text":"Not yet written \u00b6","title":"Not yet written"},{"location":"walk_scheduling/#not-yet-written","text":"","title":"Not yet written"},{"location":"walk_static/","text":"Hosting Static Files \u00b6 Generally if you'd like to use your Django project to present a User Interface (UI) then you'll need to display Images and CSS and serve Javascript files. These are known as static files and to deliver them using Zappa is unlike the traditional method of hosting the static files on a Linux or Windows box. Static files and Code on a Single Server \u00b6 A very common configuration you may see recommended is to have your Django project deployed on a server with your static files . Then the advice is to have your web server software (apache, nginx, or other) have special mechanisms to directly serve the static files. The idea is to have the fast web server software handle delivering the static images to clients and the comparatively slow Django/python code process the more complex views and page content. Because Zappa runs in the serverless lambda environment, this approach is not feasible since you cannot configure the web server to handle various url paths differently. Thus another approach must be taken. Leveraging WSGI app to serve files \u00b6 The situation where one does not have access to the web server software configuration is more common than one may think. Hosting in a shared environment, or on Platform as a Service (PaaS) like OpenShift may prevent full configuration of the web server to effectively serve static files. There are ways to leverage the WSGI application (Django for us) and instruct it to serve static files. Normally, Django treats URL requests as an opportunity to run python code. And the python code may have complex logic. But there is a model called WhiteNoise . It is an app that will minimize the python code processing to more efficiently serve static files. Thus no external web server software configuration is required. While perhaps not as optimal as having the web server hosting the files, this method has been used in production effectively. Using external services to serve files \u00b6 Finally, there is an option to use an external service to serve static files . This is the option that is the subject of this walkthrough. While any external service that serves files over HTTP could work, the focus for us will be to leverage the AWS service of S3 and the Content Delivery Network (CDN) of CloudFront to meet our needs. The S3 service will contain our files and provide the fundamental HTTP/HTTPS service. This alone will suffice for many recreational projects, but more professional project will want to leverage CloudFront to provide caching, faster delivery, and better protection of assets. Note that much of this information was pulled from https://www.caktusgroup.com/blog/2014/11/10/Using-Amazon-S3-to-store-your-Django-sites-static-and-media-files/ Using a CDN for the entire project \u00b6 There are also advantages to serving the entire Django project (Lambda functions and S3 Static files) via the CloudFront CDN. This option will not be covered in this Walkthrough. Setup and Prerequisites \u00b6 Make sure you understand and execute the Core Django Walkthrough first. This Walkthrough builds upon that. Setup Amazon Account \u00b6 You will need an AWS S3 bucket to host your static files. This should not be the same as your S3 bucket used by zappa to upload your code. The reason is that you will be making some modifications to the S3 bucket to properly use HTTP to serve files. Create an S3 bucket and name it something like zappa-static . You may name it anything you like but for the purposes of this walkthrough we will use zappa-static . Replace all occurrences of this string with your chosen bucket name. Configure CORS \u00b6 CORS is an HTTP standard that enables browsers to pull content from different sources on a single web page. Because our Django Lambda views are hosted on a different URL, we must enable the CORS setting on the S3 bucket holding our static assets to allow the files to be pulled. Go to your S3 bucket properties, and under \"Permissions\", click on \"Add CORS Configuration\". Paste this in: <CORSConfiguration> <CORSRule> <AllowedOrigin>*</AllowedOrigin> <AllowedMethod>GET</AllowedMethod> <MaxAgeSeconds>3000</MaxAgeSeconds> <AllowedHeader>Authorization</AllowedHeader> </CORSRule> </CORSConfiguration> Note that this CORS policy is very open and simple. If you have a production site, you will probably want to narrow the scope of CORS or leverage a CDN. Configure Django Project \u00b6 Install modules \u00b6 In order to re-use existing modules freely available, we will use the django-s3-storage package to handle the management of files to and from AWS S3. So first you must install it. Don't forget to activate your virtual environment pip install django-s3-storage And thus you should take the corresponding package versions reported by pip freeze into the requirements.txt file. At the time of this writing, the additional lines would be: ... django-s3-storage==0.12.4 ... Add Django-S3-Storage to the INSTALLED_APPS in settings.py \u00b6 Edit your settings.py file to include django-s3-storage. Note it's called 'django_s3_storage' as an app. INSTALLED_APPS = ( ..., 'django_s3_storage', ) Configure Django-S3-Storage in settings.py \u00b6 Add these lines anywhere in your settings.py. These values instruct django-s3-storage to properly configure a basic setup for leveraging S3. YOUR_S3_BUCKET = \"zappa-static\" STATICFILES_STORAGE = \"django_s3_storage.storage.StaticS3Storage\" AWS_S3_BUCKET_NAME_STATIC = YOUR_S3_BUCKET # These next two lines will serve the static files directly # from the s3 bucket AWS_S3_CUSTOM_DOMAIN = '%s.s3.amazonaws.com' % YOUR_S3_BUCKET STATIC_URL = \"https://%s/\" % AWS_S3_CUSTOM_DOMAIN # OR...if you create a fancy custom domain for your static files use: #AWS_S3_PUBLIC_URL_STATIC = \"https://static.zappaguide.com/\" Push your static files to the cloud \u00b6 The funny thing about zappa is that generally you have a working local environment and a working lambda environment. In theory either location can push the static files to the cloud. Using your local environment: python manage.py collectstatic --noinput Or to instruct your zappa-powered AWS lambda environment to do it for you (don't forget to push your code changes first) zappa update dev zappa manage dev \"collectstatic --noinput\" Test with the admin \u00b6 Once you have pushed your static files to S3, you can visit the admin site for your Django project to test if it worked. Appending /admin/ to your zappa project you can now browse to the admin site and watch the css being loaded just fine. Next Steps \u00b6 Well great, now you have a working Django site that processes views and can serve static files. But you can't login because there is no database. Continue through the walkthroughs to complete a fully functional website. Additional HTTP Settings \u00b6 As mentioned above you probably want to ensure a valid CORS policy is in place for anything resembling production. In addition there are many default HTTP headers that can be served with your static files to ensure proper caching and so forth. The example format in your settings.py file is: AWS_S3_MAX_AGE_SECONDS_STATIC = \"94608000\" See the django-s3-storage for more settings.","title":"Hosting Static Files"},{"location":"walk_static/#hosting-static-files","text":"Generally if you'd like to use your Django project to present a User Interface (UI) then you'll need to display Images and CSS and serve Javascript files. These are known as static files and to deliver them using Zappa is unlike the traditional method of hosting the static files on a Linux or Windows box.","title":"Hosting Static Files"},{"location":"walk_static/#static-files-and-code-on-a-single-server","text":"A very common configuration you may see recommended is to have your Django project deployed on a server with your static files . Then the advice is to have your web server software (apache, nginx, or other) have special mechanisms to directly serve the static files. The idea is to have the fast web server software handle delivering the static images to clients and the comparatively slow Django/python code process the more complex views and page content. Because Zappa runs in the serverless lambda environment, this approach is not feasible since you cannot configure the web server to handle various url paths differently. Thus another approach must be taken.","title":"Static files and Code on a Single Server"},{"location":"walk_static/#leveraging-wsgi-app-to-serve-files","text":"The situation where one does not have access to the web server software configuration is more common than one may think. Hosting in a shared environment, or on Platform as a Service (PaaS) like OpenShift may prevent full configuration of the web server to effectively serve static files. There are ways to leverage the WSGI application (Django for us) and instruct it to serve static files. Normally, Django treats URL requests as an opportunity to run python code. And the python code may have complex logic. But there is a model called WhiteNoise . It is an app that will minimize the python code processing to more efficiently serve static files. Thus no external web server software configuration is required. While perhaps not as optimal as having the web server hosting the files, this method has been used in production effectively.","title":"Leveraging WSGI app to serve files"},{"location":"walk_static/#using-external-services-to-serve-files","text":"Finally, there is an option to use an external service to serve static files . This is the option that is the subject of this walkthrough. While any external service that serves files over HTTP could work, the focus for us will be to leverage the AWS service of S3 and the Content Delivery Network (CDN) of CloudFront to meet our needs. The S3 service will contain our files and provide the fundamental HTTP/HTTPS service. This alone will suffice for many recreational projects, but more professional project will want to leverage CloudFront to provide caching, faster delivery, and better protection of assets. Note that much of this information was pulled from https://www.caktusgroup.com/blog/2014/11/10/Using-Amazon-S3-to-store-your-Django-sites-static-and-media-files/","title":"Using external services to serve files"},{"location":"walk_static/#using-a-cdn-for-the-entire-project","text":"There are also advantages to serving the entire Django project (Lambda functions and S3 Static files) via the CloudFront CDN. This option will not be covered in this Walkthrough.","title":"Using a CDN for the entire project"},{"location":"walk_static/#setup-and-prerequisites","text":"Make sure you understand and execute the Core Django Walkthrough first. This Walkthrough builds upon that.","title":"Setup and Prerequisites"},{"location":"walk_static/#setup-amazon-account","text":"You will need an AWS S3 bucket to host your static files. This should not be the same as your S3 bucket used by zappa to upload your code. The reason is that you will be making some modifications to the S3 bucket to properly use HTTP to serve files. Create an S3 bucket and name it something like zappa-static . You may name it anything you like but for the purposes of this walkthrough we will use zappa-static . Replace all occurrences of this string with your chosen bucket name.","title":"Setup Amazon Account"},{"location":"walk_static/#configure-cors","text":"CORS is an HTTP standard that enables browsers to pull content from different sources on a single web page. Because our Django Lambda views are hosted on a different URL, we must enable the CORS setting on the S3 bucket holding our static assets to allow the files to be pulled. Go to your S3 bucket properties, and under \"Permissions\", click on \"Add CORS Configuration\". Paste this in: <CORSConfiguration> <CORSRule> <AllowedOrigin>*</AllowedOrigin> <AllowedMethod>GET</AllowedMethod> <MaxAgeSeconds>3000</MaxAgeSeconds> <AllowedHeader>Authorization</AllowedHeader> </CORSRule> </CORSConfiguration> Note that this CORS policy is very open and simple. If you have a production site, you will probably want to narrow the scope of CORS or leverage a CDN.","title":"Configure CORS"},{"location":"walk_static/#configure-django-project","text":"","title":"Configure Django Project"},{"location":"walk_static/#install-modules","text":"In order to re-use existing modules freely available, we will use the django-s3-storage package to handle the management of files to and from AWS S3. So first you must install it. Don't forget to activate your virtual environment pip install django-s3-storage And thus you should take the corresponding package versions reported by pip freeze into the requirements.txt file. At the time of this writing, the additional lines would be: ... django-s3-storage==0.12.4 ...","title":"Install modules"},{"location":"walk_static/#add-django-s3-storage-to-the-installed_apps-in-settingspy","text":"Edit your settings.py file to include django-s3-storage. Note it's called 'django_s3_storage' as an app. INSTALLED_APPS = ( ..., 'django_s3_storage', )","title":"Add Django-S3-Storage to the INSTALLED_APPS in settings.py"},{"location":"walk_static/#configure-django-s3-storage-in-settingspy","text":"Add these lines anywhere in your settings.py. These values instruct django-s3-storage to properly configure a basic setup for leveraging S3. YOUR_S3_BUCKET = \"zappa-static\" STATICFILES_STORAGE = \"django_s3_storage.storage.StaticS3Storage\" AWS_S3_BUCKET_NAME_STATIC = YOUR_S3_BUCKET # These next two lines will serve the static files directly # from the s3 bucket AWS_S3_CUSTOM_DOMAIN = '%s.s3.amazonaws.com' % YOUR_S3_BUCKET STATIC_URL = \"https://%s/\" % AWS_S3_CUSTOM_DOMAIN # OR...if you create a fancy custom domain for your static files use: #AWS_S3_PUBLIC_URL_STATIC = \"https://static.zappaguide.com/\"","title":"Configure Django-S3-Storage in settings.py"},{"location":"walk_static/#push-your-static-files-to-the-cloud","text":"The funny thing about zappa is that generally you have a working local environment and a working lambda environment. In theory either location can push the static files to the cloud. Using your local environment: python manage.py collectstatic --noinput Or to instruct your zappa-powered AWS lambda environment to do it for you (don't forget to push your code changes first) zappa update dev zappa manage dev \"collectstatic --noinput\"","title":"Push your static files to the cloud"},{"location":"walk_static/#test-with-the-admin","text":"Once you have pushed your static files to S3, you can visit the admin site for your Django project to test if it worked. Appending /admin/ to your zappa project you can now browse to the admin site and watch the css being loaded just fine.","title":"Test with the admin"},{"location":"walk_static/#next-steps","text":"Well great, now you have a working Django site that processes views and can serve static files. But you can't login because there is no database. Continue through the walkthroughs to complete a fully functional website.","title":"Next Steps"},{"location":"walk_static/#additional-http-settings","text":"As mentioned above you probably want to ensure a valid CORS policy is in place for anything resembling production. In addition there are many default HTTP headers that can be served with your static files to ensure proper caching and so forth. The example format in your settings.py file is: AWS_S3_MAX_AGE_SECONDS_STATIC = \"94608000\" See the django-s3-storage for more settings.","title":"Additional HTTP Settings"}]}